{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled23.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/eDreams/blob/master/eDreams_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17LuXi1voKCf",
        "colab_type": "text"
      },
      "source": [
        "# Install & Load Main Python libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgBiQdX-a8wy",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/a-deep-dive-into-imbalanced-data-over-sampling-f1167ed74b5\n",
        "\n",
        "https://towardsdatascience.com/from-zero-to-hero-in-xgboost-tuning-e48b59bfaf58\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/xgboost-in-python\n",
        "\n",
        "https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
        "\n",
        "https://towardsdatascience.com/probability-calibration-for-imbalanced-dataset-64af3730eaab\n",
        "\n",
        "https://towardsdatascience.com/dealing-with-imbalanced-classes-in-machine-learning-d43d6fa19d2\n",
        "\n",
        "Dealing with Highly Imbalanced Classes in Classification Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIMVpjquns-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhymf5HmfuyW",
        "colab_type": "text"
      },
      "source": [
        "# Load dataframes: training & test sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWfL-XJFnZIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_train= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/train.csv?token=AGDJQ66URBHOZ6URJ3OP4XC53PUOK\"\n",
        "url_test= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/test.csv?token=AGDJQ6275IPQHG2XKLMKSU253PUQ4\"\n",
        "\n",
        "# Stacking training and validation samples for a single treatment\n",
        "df_train= pd.read_csv(url_train, sep= \";\", index_col= 'ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "df_test= pd.read_csv(url_test, sep= \";\", index_col= 'ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "\n",
        "# Resetting the test sample indices\n",
        "df_test['ID']= range(50000, 80000)\n",
        "df_test.set_index('ID',inplace=True)\n",
        "\n",
        "# merge train and test\n",
        "df = df_train.append(df_test, sort= True)\n",
        "\n",
        "# Records training and test dataframe indexes to separate these dataframes later\n",
        "train_index = df_train.index\n",
        "test_index = df_test.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EItCRxK9OWVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbkvqUL-PMmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDIkBDEaP_eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puYrD8S-QnuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpAcrYpUQEL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWPMAIX1vMuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDANOjiKf4Qh",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrH6yLyI_LIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T= df.copy()\n",
        "# Capturing the Company: First 2 positions of WEBSITE.\n",
        "df_T['COMPANY']= df_T['WEBSITE'].str[0:2].astype(str)\n",
        "\n",
        "# Capturing the Country: rest of the string of WEBSITE.\n",
        "df_T['COUNTRY']= df_T['WEBSITE'].str[2:len(df['WEBSITE'])].astype(str)\n",
        "\n",
        "df_T.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbiq3bb5BFOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COMPANY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL2tFUwhBdwB",
        "colab_type": "text"
      },
      "source": [
        "There's no 'TL'. So I'll replace 'TL' by 'MV'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Wf9MUqBsof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COMPANY']= df_T['COMPANY'].replace('TL', 'MV')\n",
        "df_T['COMPANY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyo-zI5aAz62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE3dyQM56HBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Corrigindo Poland Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'PLC': 'PL'})\n",
        "\n",
        "# Corrigindo France Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'FRC': 'FR'})\n",
        "\n",
        "# Corrigindo DEC Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'DEC': 'DE'})\n",
        "\n",
        "# Corrigindo DEC Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'DKC': 'DK'})\n",
        "\n",
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P86wEaspCljP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_T['COUNTRY']= df_T['COUNTRY'].replace(['PLC', 'DEC', 'DKC', 'FRC'], 'MV')\n",
        "#df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjGHXqYODAbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COUNTRY']= df_T['COUNTRY'].replace(['UK'], 'GB')\n",
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QRlW3cf6M5",
        "colab_type": "text"
      },
      "source": [
        "## Treating date variables\n",
        "> Since there is no information regarding the year of the transaction, I will assume that the transactions are from 2018 or 2019. I will assign the year conveniently from the analysis of the variables DEPARTURE and ARRIVAL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myZk676JnqrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2= df_T.copy()\n",
        "df2['DEPARTURE_WITH_YEAR']= df2['DEPARTURE'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR']= df2['ARRIVAL'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= df2['ARRIVAL'] +'/2019'\n",
        "\n",
        "df2['DEPARTURE_WITH_YEAR']= pd.to_datetime(df2['DEPARTURE_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR_FIXED'])\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPw1d6SgukXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2['MONTH_DEPARTURE']= df2['DEPARTURE_WITH_YEAR'].dt.month\n",
        "df2= df2.drop(['DEPARTURE_WITH_YEAR', 'ARRIVAL_WITH_YEAR', 'ARRIVAL_WITH_YEAR_FIXED', 'WEBSITE', 'DEPARTURE','ARRIVAL','TIMESTAMP'], axis= 1)\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKGY0hPj8uAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting column DISTANCE to numeric. For this purpose, I'll cut the distance in the \",\"\n",
        "df3= df2.copy()\n",
        "df3[['DISTANCE_2','DISTANCE_REST']] = df3['DISTANCE'].str.split(\",\",expand=True)\n",
        "df3['DISTANCE_2']= pd.to_numeric(df3['DISTANCE_2'])\n",
        "df3[['HAUL_TYPE','DISTANCE','DISTANCE_2','DISTANCE_REST']].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ2buWxxBEGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3= df3.drop(columns= ['DISTANCE_REST','DISTANCE'], axis= 1)\n",
        "df3= df3.rename({'DISTANCE_2': 'DISTANCE'}, axis=1)\n",
        "df3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1adzZo47EwjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking Missing Values\n",
        "df3.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaAjeTcnH24a",
        "colab_type": "text"
      },
      "source": [
        "Let's treat Missing Values in DISTANCE and DEVICE below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFerujs2OUYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing NaN's from DISTANCE\n",
        "df3['DISTANCE'] = np.where((df3['DISTANCE'].isnull()), df3['DISTANCE'].median(), df3['DISTANCE'])\n",
        "\n",
        "# Replacing NaN's of DEVICE with 'NO_DEVICE'\n",
        "df3[\"DEVICE\"].fillna(\"NO_DEVICE\", inplace= True)\n",
        "\n",
        "df3.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5nGTv5SF-JA",
        "colab_type": "text"
      },
      "source": [
        "# Binning numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpkwv3XC5lkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBGPZOyO3taE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df3.copy()\n",
        "df4['DISTANCE_BUCKET'] = pd.cut(df4['DISTANCE'], bins= 10, labels= [1,2,3,4,5,6,7,8,9,10])\n",
        "df4= df4.drop(['DISTANCE'], axis= 1)\n",
        "df4['DISTANCE_BUCKET'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJxojEs-5Ou4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIf8bQdKGFbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df5= df4.copy()\n",
        "\n",
        "d_Var_Target= {True: 1, False: 0}\n",
        "df5['EXTRA_BAGGAGE']= df5['EXTRA_BAGGAGE'].map(d_Var_Target)\n",
        "df5['SMS']= df5['SMS'].map(d_Var_Target)\n",
        "df5['TRAIN']= df5['TRAIN'].map(d_Var_Target)\n",
        "df5.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BknNArv1eyBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df6= df5.copy()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df6= pd.get_dummies(data=df6, columns=['DEVICE', 'HAUL_TYPE', 'PRODUCT', 'TRIP_TYPE', 'COMPANY', 'COUNTRY', 'DISTANCE_BUCKET'])\n",
        "\n",
        "#df6['DEVICE']= LabelEncoder().fit_transform(df6['DEVICE'])\n",
        "#df6['HAUL_TYPE']= LabelEncoder().fit_transform(df6['HAUL_TYPE'])\n",
        "#df6['PRODUCT']= LabelEncoder().fit_transform(df6['PRODUCT'])\n",
        "#df6['TRIP_TYPE']= LabelEncoder().fit_transform(df6['TRIP_TYPE'])\n",
        "#df6['COMPANY']= LabelEncoder().fit_transform(df6['COMPANY'])\n",
        "#df6['COUNTRY']= LabelEncoder().fit_transform(df6['COUNTRY'])\n",
        "#df6['DISTANCE_BUCKET']= LabelEncoder().fit_transform(df6['DISTANCE_BUCKET'])\n",
        "df6.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbFDWd_JEZw",
        "colab_type": "text"
      },
      "source": [
        "## Treating categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xph3AArLwjcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_Vars_Obj= list(df6.select_dtypes(include=['category', 'object']).columns)\n",
        "l_Vars_Obj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGzOYgPYMv6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for col in l_Vars_Obj:\n",
        "#    df11[col]= LabelEncoder().fit_transform(df11[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IoUBan0QJWW",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwJtOjFmQOUy",
        "colab_type": "text"
      },
      "source": [
        "## Train/Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk_vdqSq6qD-",
        "colab_type": "text"
      },
      "source": [
        "### Balancing the training sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM0lsoJd68Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgDzwv35xmn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBahHsJwvKc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X= df6.iloc[train_index, :]\n",
        "y= X[['EXTRA_BAGGAGE']].astype(int)\n",
        "\n",
        "X= X.drop('EXTRA_BAGGAGE', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYnIQwlsZLGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)\n",
        "\n",
        "i_Seed= 20111974\n",
        "i_CV= 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmE-ycLi73_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying RandomUnderSampler\n",
        "X_Resampled0, y_Resampled0 = RandomUnderSampler(random_state= i_Seed).fit_resample(X_train, y_train)\n",
        "#print(sorted(Counter(y_Resampled0).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdSoEGznOXKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying SMOTE to our data and checking the class counts\n",
        "X_Resampled1, y_Resampled1 = SMOTE(random_state= i_Seed).fit_resample(X_train, y_train)\n",
        "#print(sorted(Counter(y_Resampled1).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOmLKRJLZIGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying ADASYN\n",
        "X_Resampled2, y_Resampled2 = ADASYN(random_state= i_Seed).fit_resample(X_train, y_train)\n",
        "#print(sorted(Counter(y_Resampled2).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qeibTMgZRGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BorderlineSMOTE\n",
        "X_Resampled3, y_Resampled3 = BorderlineSMOTE(random_state= i_Seed).fit_resample(X_train, y_train)\n",
        "#print(sorted(Counter(y_Resampled3).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSkWEZo_fndk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports \n",
        "X_Resampled4, y_Resampled4 = RandomOverSampler(random_state= i_Seed).fit_resample(X_train, y_train)\n",
        "#print(sorted(Counter(y_Resampled4).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS6jPT2q2LvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um6eDoo5cfGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(X_Resampled0, y_Resampled0, test_size= 0.1, stratify= y_Resampled0, )\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_Resampled1, y_Resampled1, test_size= 0.1, stratify= y_Resampled1)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_Resampled2, y_Resampled2, test_size= 0.1, stratify= y_Resampled2)\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_Resampled3, y_Resampled3, test_size= 0.1, stratify= y_Resampled3)\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X_Resampled4, y_Resampled4, test_size= 0.1, stratify= y_Resampled4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGvmZ07J6j_H",
        "colab_type": "text"
      },
      "source": [
        "Next, we will apply the following estimators / classifiers to the training sample:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6alHA0z9cHe",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNO3IhZO905D",
        "colab_type": "text"
      },
      "source": [
        "## Interpretation\n",
        "> A good F1 score means that you have low false positives and low false negatives, so you’re correctly identifying real threats and you are not disturbed by false alarms. \n",
        ">> An F1 score is considered perfect when it’s 1, while the model is a total failure when it’s 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kYW_yzqvNdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import f1_score, accuracy_score, average_precision_score, confusion_matrix, precision_score, recall_score, log_loss, cohen_kappa_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAGezEXE-ljX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=False,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize= (8,8),\n",
        "                          cmap='Blues'):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5k__EnD7tGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definindo a função para o GridSearchCV\n",
        "def GridSearchOptimizer(modelo, d_Parametros, X_train, y_train, X_test, y_test, cv= i_CV):\n",
        "    Model_GridSearchCV = GridSearchCV(modelo, d_Parametros, cv= i_CV, n_jobs= -1, verbose= 10, scoring= 'f1')\n",
        "    Model_GridSearchCV.fit(X_train, y_train)\n",
        "    \n",
        "    # Parâmetros que otimizam a classificação:\n",
        "    print(f'\\nParametros otimizados: {Model_GridSearchCV.best_params_}')\n",
        "    \n",
        "    Model_Opt= XGBoostingClassifier(learning_rate= Model_GridSearchCV.best_params_['learning_rate'],\n",
        "                                        max_depth= Model_GridSearchCV.best_params_['max_depth'],\n",
        "                                        subsample= Model_GridSearchCV.best_params_['subsample'],\n",
        "                                        gamma= Model_GridSearchCV.best_params_['gamma'],\n",
        "                                        reg_lambda= Model_GridSearchCV.best_params_['reg_lambda'],\n",
        "                                        reg_alpha= Model_GridSearchCV.best_params_['reg_alpha'],\n",
        "                                        n_estimators= Model_GridSearchCV.best_params_['n_estimators'],\n",
        "                                        min_child_weight= Model_GridSearchCV.best_params_['min_child_weight'])\n",
        "       \n",
        "    # Treina novamente usando os parametros otimizados...\n",
        "    Model_Opt.fit(X_train, y_train)\n",
        "\n",
        "    # Cross-Validation com 10 folds\n",
        "    print(f'\\n********* CROSS-VALIDATION ***********')\n",
        "    a_Scores_CV = cross_val_score(Model_Opt, X_train, y_train, cv= i_CV)\n",
        "    print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV.mean(),4)}')\n",
        "    print(f'std médio das Acurácias calculadas pelo CV: {100*round(a_Scores_CV.std(),4)}')\n",
        "\n",
        "    # Faz predições com os parametros otimizados...\n",
        "    y_pred = Model_Opt.predict(X_test)\n",
        "  \n",
        "    # Importância das COLUNAS\n",
        "    print(f'\\n********* IMPORTÂNCIA DAS COLUNAS ***********')\n",
        "    df_Importance= pd.DataFrame(zip(l_Col_Names, Model_Opt.feature_importances_), columns= ['coluna', 'importancia'])\n",
        "    df_Importance= df_Importance.sort_values(by= ['importancia'], ascending=False)\n",
        "    print(df_Importance)\n",
        "\n",
        "    # Matriz de Confusão\n",
        "    print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    cf_labels = ['True Neg','False Pos','False Neg','True Pos']\n",
        "    cf_categories = ['Zero', 'One']\n",
        "    make_confusion_matrix(cf_matrix, group_names= cf_labels, categories= cf_categories)\n",
        "\n",
        "    return Model_Opt, Model_GridSearchCV.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GccQLum7M8NN",
        "colab_type": "text"
      },
      "source": [
        "# XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2EknshxXcGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Instancia...\n",
        "Model_XGB= XGBClassifier(learning_rate=0.01,  \n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      max_depth= 3, min_child_weight= 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w73GwNq4tPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_f1(cutoff):\n",
        "    def f1_cutoff(clf, X, y):\n",
        "        y_pred= cutoff_predict(clf, cutoff)\n",
        "        return sklearn.metrics.f1_score(y_pred, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_-bsSbZVgvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_CV= 3\n",
        "\n",
        "l_Scores= []\n",
        "l_Scores0= []\n",
        "l_Scores1= []\n",
        "l_Scores2= []\n",
        "l_Scores3= []\n",
        "l_Scores4= []\n",
        "f1_Score= []\n",
        "\n",
        "for cutoff in np.arange(0.1, 0.95, 0.1):\n",
        "    Model_XGB= XGBClassifier(learning_rate=0.01,  \n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      max_depth= 3, min_child_weight= 2)\n",
        "    \n",
        "    a_Scores_CV=  cross_val_score(Model_XGB, X_train, y_train, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV0= cross_val_score(Model_XGB, X_train0, y_train0, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV1= cross_val_score(Model_XGB, X_train1, y_train1, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV2= cross_val_score(Model_XGB, X_train2, y_train2, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV3= cross_val_score(Model_XGB, X_train3, y_train3, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV4= cross_val_score(Model_XGB, X_train4, y_train4, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "\n",
        "    l_Scores.append(a_Scores_CV)\n",
        "    l_Scores0.append(a_Scores_CV0)\n",
        "    l_Scores1.append(a_Scores_CV1)\n",
        "    l_Scores2.append(a_Scores_CV2)\n",
        "    l_Scores3.append(a_Scores_CV3)\n",
        "    l_Scores4.append(a_Scores_CV4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfFch2xpAY9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV.mean(),4)}; std médio das Acurácias calculadas pelo CV: {100*round(a_Scores_CV.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV0.mean(),4)}; std médio das Acurácias calculadas pelo CV0: {100*round(a_Scores_CV0.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV1.mean(),4)}; std médio das Acurácias calculadas pelo CV1: {100*round(a_Scores_CV1.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV2.mean(),4)}; std médio das Acurácias calculadas pelo CV2: {100*round(a_Scores_CV2.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV3.mean(),4)}; std médio das Acurácias calculadas pelo CV3: {100*round(a_Scores_CV3.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV4.mean(),4)}; std médio das Acurácias calculadas pelo CV4: {100*round(a_Scores_CV4.std(),4)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3ScO_kQFkZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report \n",
        "\n",
        "def Mostra_Resultado(X_train, y_train, X_test, y_test):\n",
        "    Model_XGB= XGBClassifier(learning_rate=0.01,  \n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      max_depth= 3, min_child_weight= 2)\n",
        "    \n",
        "    Model_XGB.fit(X_train, y_train)\n",
        "    y_pred=  Model_XGB.predict(X_test)\n",
        "    results = confusion_matrix(y_test, y_pred)\n",
        "    print(results)\n",
        "    print(f'Accuracy Score : {accuracy_score(y_test, y_pred)}') \n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7HaTTdEL_DK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1xQ2QkbMGsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train0, y_train0, X_test0, y_test0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn4l9sAgMIZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train1, y_train1, X_test1, y_test1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_cGvb6XMIju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train2, y_train2, X_test2, y_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdms8mnkMIpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train3, y_train3, X_test3, y_test3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNTdaoiMMIv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train4, y_train4, X_test4, y_test4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIintw5gMIgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKKBid2eE9wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate feature importances\n",
        "importances = Model_XGB.feature_importances_\n",
        "importances[0:45]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvdSbFiFNLCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dicionário de parâmetros para XGBoost:\n",
        "d_Parametros_XGB = {'min_child_weight': [1,3,5,7],\n",
        "                    'n_estimators': [100,250,500,1000],\n",
        "                    'subsample': [0.2, 0.4, 0.5, 0.6, 0.7],\n",
        "                    'max_depth': [2,4,7,10],\n",
        "                    'learning_rate': [0.1, 0.01, 0.001]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PykqgO4qV3kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Invoca a função\n",
        "Model_XGB, best_params= GridSearchOptimizer(Model_XGB, d_Parametros_XGB, X_train0, y_train0, X_test0, y_test0, cv= i_CV)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}