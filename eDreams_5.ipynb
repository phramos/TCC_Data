{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled23.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/eDreams/blob/master/eDreams_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17LuXi1voKCf",
        "colab_type": "text"
      },
      "source": [
        "# Install & Load Main Python libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgBiQdX-a8wy",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/a-deep-dive-into-imbalanced-data-over-sampling-f1167ed74b5\n",
        "\n",
        "https://towardsdatascience.com/from-zero-to-hero-in-xgboost-tuning-e48b59bfaf58\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/xgboost-in-python\n",
        "\n",
        "https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
        "\n",
        "https://towardsdatascience.com/probability-calibration-for-imbalanced-dataset-64af3730eaab\n",
        "\n",
        "https://towardsdatascience.com/dealing-with-imbalanced-classes-in-machine-learning-d43d6fa19d2\n",
        "\n",
        "Dealing with Highly Imbalanced Classes in Classification Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIMVpjquns-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhymf5HmfuyW",
        "colab_type": "text"
      },
      "source": [
        "# Load dataframes: training & test sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWfL-XJFnZIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_train= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/train.csv?token=AGDJQ66URBHOZ6URJ3OP4XC53PUOK\"\n",
        "url_test= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/test.csv?token=AGDJQ6275IPQHG2XKLMKSU253PUQ4\"\n",
        "\n",
        "# Stacking training and validation samples for a single treatment\n",
        "df_train= pd.read_csv(url_train, sep= \";\", index_col= 'ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "df_test= pd.read_csv(url_test, sep= \";\", index_col= 'ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "\n",
        "# Resetting the test sample indices\n",
        "df_test['ID']= range(50000, 80000)\n",
        "df_test.set_index('ID',inplace=True)\n",
        "\n",
        "# merge train and test\n",
        "df = df_train.append(df_test, sort= True)\n",
        "\n",
        "# Records training and test dataframe indexes to separate these dataframes later\n",
        "train_index = df_train.index\n",
        "test_index = df_test.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EItCRxK9OWVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbkvqUL-PMmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDIkBDEaP_eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puYrD8S-QnuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpAcrYpUQEL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWPMAIX1vMuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDANOjiKf4Qh",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrH6yLyI_LIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T= df.copy()\n",
        "\n",
        "d_Var_Target= {True: 1, False: 0}\n",
        "df_T['EXTRA_BAGGAGE']= df_T['EXTRA_BAGGAGE'].map(d_Var_Target)\n",
        "df_T['SMS']= df_T['SMS'].map(d_Var_Target)\n",
        "df_T['TRAIN']= df_T['TRAIN'].map(d_Var_Target).astype(str)\n",
        "\n",
        "# Capturing the Company: First 2 positions of WEBSITE.\n",
        "df_T['COMPANY']= df_T['WEBSITE'].str[0:2].astype(str)\n",
        "\n",
        "# Capturing the Country: rest of the string of WEBSITE.\n",
        "df_T['COUNTRY']= df_T['WEBSITE'].str[2:len(df['WEBSITE'])].astype(str)\n",
        "\n",
        "df_T.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbiq3bb5BFOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COMPANY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL2tFUwhBdwB",
        "colab_type": "text"
      },
      "source": [
        "There's no 'TL'. So I'll replace 'TL' by 'MV'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Wf9MUqBsof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COMPANY']= df_T['COMPANY'].replace('TL', 'MV')\n",
        "df_T['COMPANY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyo-zI5aAz62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE3dyQM56HBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Corrigindo Poland Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'PLC': 'PL'})\n",
        "\n",
        "# Corrigindo France Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'FRC': 'FR'})\n",
        "\n",
        "# Corrigindo DEC Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'DEC': 'DE'})\n",
        "\n",
        "# Corrigindo DEC Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'DKC': 'DK'})\n",
        "\n",
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjGHXqYODAbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COUNTRY']= df_T['COUNTRY'].replace(['UK'], 'GB')\n",
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyYjQ84s9Skv",
        "colab_type": "text"
      },
      "source": [
        "# Chi-Squared test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP2vbEjl9Ryh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.stats as stats\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "class ChiSquare:\n",
        "    def __init__(self, dataframe):\n",
        "        self.df = dataframe\n",
        "        self.p = None #P-Value\n",
        "        self.chi2 = None #Chi Test Statistic\n",
        "        self.dof = None\n",
        "        \n",
        "        self.dfObserved = None\n",
        "        self.dfExpected = None\n",
        "        \n",
        "    def _print_chisquare_result(self, colX, alpha):\n",
        "        result = \"\"\n",
        "        if self.p<alpha:\n",
        "            result=\"{0} is IMPORTANT for Prediction\".format(colX)\n",
        "        else:\n",
        "            result=\"{0} is NOT an important predictor. (Discard {0} from model)\".format(colX)\n",
        "\n",
        "        print(result)\n",
        "        \n",
        "    def TestIndependence(self,colX,colY, alpha=0.05):\n",
        "        X = self.df[colX].astype(str)\n",
        "        Y = self.df[colY].astype(str)\n",
        "        \n",
        "        self.dfObserved = pd.crosstab(Y,X) \n",
        "        chi2, p, dof, expected = stats.chi2_contingency(self.dfObserved.values)\n",
        "        self.p = p\n",
        "        self.chi2 = chi2\n",
        "        self.dof = dof \n",
        "        \n",
        "        self.dfExpected = pd.DataFrame(expected, columns=self.dfObserved.columns, index = self.dfObserved.index)\n",
        "        \n",
        "        self._print_chisquare_result(colX,alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QRlW3cf6M5",
        "colab_type": "text"
      },
      "source": [
        "## Treating date variables\n",
        "> Since there is no information regarding the year of the transaction, I will assume that the transactions are from 2018 or 2019. I will assign the year conveniently from the analysis of the variables DEPARTURE and ARRIVAL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myZk676JnqrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2= df_T.copy()\n",
        "df2['DEPARTURE_WITH_YEAR']= df2['DEPARTURE'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR']= df2['ARRIVAL'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= df2['ARRIVAL'] +'/2019'\n",
        "\n",
        "df2['DEPARTURE_WITH_YEAR']= pd.to_datetime(df2['DEPARTURE_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR_FIXED'])\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPw1d6SgukXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2['MONTH_DEPARTURE']= df2['DEPARTURE_WITH_YEAR'].dt.month\n",
        "df2= df2.drop(['DEPARTURE_WITH_YEAR', 'ARRIVAL_WITH_YEAR', 'ARRIVAL_WITH_YEAR_FIXED', 'WEBSITE', 'DEPARTURE','ARRIVAL','TIMESTAMP'], axis= 1)\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKGY0hPj8uAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting column DISTANCE to numeric. For this purpose, I'll cut the distance in the \",\"\n",
        "df3= df2.copy()\n",
        "df3[['DISTANCE_2','DISTANCE_REST']] = df3['DISTANCE'].str.split(\",\",expand=True)\n",
        "df3['DISTANCE_2']= pd.to_numeric(df3['DISTANCE_2'])\n",
        "df3[['HAUL_TYPE','DISTANCE','DISTANCE_2','DISTANCE_REST']].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ2buWxxBEGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3= df3.drop(columns= ['DISTANCE_REST','DISTANCE'], axis= 1)\n",
        "df3= df3.rename({'DISTANCE_2': 'DISTANCE'}, axis=1)\n",
        "df3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1adzZo47EwjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking Missing Values\n",
        "df3.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaAjeTcnH24a",
        "colab_type": "text"
      },
      "source": [
        "Let's treat Missing Values in DISTANCE and DEVICE below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFerujs2OUYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing NaN's from DISTANCE\n",
        "df3['DISTANCE'] = np.where((df3['DISTANCE'].isnull()), df3['DISTANCE'].median(), df3['DISTANCE'])\n",
        "\n",
        "# Replacing NaN's of DEVICE with 'NO_DEVICE'\n",
        "df3[\"DEVICE\"].fillna(\"NO_DEVICE\", inplace= True)\n",
        "\n",
        "df3.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5nGTv5SF-JA",
        "colab_type": "text"
      },
      "source": [
        "# Binning numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpkwv3XC5lkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBGPZOyO3taE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df3.copy()\n",
        "df4['DISTANCE_BUCKET'] = pd.cut(df4['DISTANCE'], bins= 10, labels= [1,2,3,4,5,6,7,8,9,10])\n",
        "df4= df4.drop(['DISTANCE'], axis= 1)\n",
        "df4['DISTANCE_BUCKET'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH5SOzWaK9bN",
        "colab_type": "text"
      },
      "source": [
        "# Balancing sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZjFacj-gLaBC",
        "colab": {}
      },
      "source": [
        "df4['EXTRA_BAGGAGE'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86SBL860NFzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4_1= df4.loc[df4['EXTRA_BAGGAGE'] == 1]\n",
        "df4_0= df4.loc[df4['EXTRA_BAGGAGE'] == 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YZf56HiyLaBG",
        "colab": {}
      },
      "source": [
        "print(df4_1.shape[0], df4_0.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsQumlCQLY4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4_0_S= df4_0.sample(n = df4_1.shape[0])\n",
        "df4_0_S.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g9vqoXILYwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4_Lab= df4_1.append(df4_0_S)\n",
        "df4_Lab.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBN0ezg_LYkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9h8oW7JGqij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize ChiSquare Class\n",
        "cT = ChiSquare(df4_Lab)\n",
        "\n",
        "#Feature Selection\n",
        "testColumns = ['HAUL_TYPE','TRIP_TYPE','COMPANY','COUNTRY','DEVICE', 'GDS', 'CHILDREN', 'ADULTS', 'NO_GDS', 'TRAIN', 'DISTANCE_BUCKET', 'SMS', 'PRODUCT', 'INFANTS', 'MONTH_DEPARTURE']\n",
        "for var in testColumns:\n",
        "    cT.TestIndependence(colX=var, colY=\"EXTRA_BAGGAGE\" )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdFrcRbnGpdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deleta as colunas sem poder preditivo da célula anterior em df4:\n",
        "df4= df4.drop(columns= ['SMS', 'PRODUCT'], axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dj0m5Rbbxyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4R0tdgubx5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_woe_iv(dataset, feature, target):\n",
        "\n",
        "    def codethem(IV):\n",
        "        if  IV < 0.02: return 'Useless'\n",
        "        elif IV >= 0.02 and IV < 0.1: return 'Weak'\n",
        "        elif IV >= 0.1 and IV < 0.3: return 'Medium'\n",
        "        elif IV > 0.3 and IV < 0.5: return 'Strong'\n",
        "        elif IV > 0.5: return 'Suspicious'\n",
        "        else: return 'None'\n",
        "\n",
        "    lst = []\n",
        "    for i in range(dataset[feature].nunique()):\n",
        "        val = list(dataset[feature].unique())[i]\n",
        "        lst.append({\n",
        "            'Value': val,\n",
        "            'All': dataset[dataset[feature] == val].count()[feature],\n",
        "            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],\n",
        "            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]\n",
        "        })\n",
        "        \n",
        "    dset = pd.DataFrame(lst)\n",
        "    dset['Distr_Good'] = dset['Good'] / dset['Good'].sum()\n",
        "    dset['Distr_Bad'] = dset['Bad'] / dset['Bad'].sum()\n",
        "    dset['WoE'] = np.log(dset['Distr_Good'] / dset['Distr_Bad'])\n",
        "    dset = dset.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
        "    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']\n",
        "    dset= dset.drop(columns= ['Distr_Good', 'Distr_Bad'], axis= 1)\n",
        "\n",
        "    dset['Predictive_Power']= dset['IV'].map(codethem)\n",
        "    iv = dset['IV'].sum()\n",
        "    \n",
        "    dset = dset.sort_values(by='IV')\n",
        "    \n",
        "    return dset, iv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baOOAjwObx3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Calcula_Predictive_Power(df_Lab, coluna):\n",
        "    print('WoE and IV for column: {}'.format(coluna))\n",
        "    df, iv = calculate_woe_iv(df_Lab, coluna, 'EXTRA_BAGGAGE')\n",
        "    print(df)\n",
        "    print('IV score: {:.2f}'.format(iv))\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcvE4Hu7bxF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'ADULTS')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgQV9J2fbxvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ajustes manuais em df4_Lab\n",
        "df4_Lab['ADULTS']= df4_Lab['ADULTS'].replace(9, 99)\n",
        "df4_Lab['ADULTS']= df4_Lab['ADULTS'].replace(0, 99)\n",
        "df4_Lab['ADULTS']= df4_Lab['ADULTS'].replace(8, 99)\n",
        "df4_Lab['ADULTS']= df4_Lab['ADULTS'].replace(7, 99)\n",
        "df4_Lab['ADULTS']= df4_Lab['ADULTS'].replace(6, 99)\n",
        "df4_Lab['ADULTS']= df4_Lab['ADULTS'].replace(5, 99)\n",
        "df4_Lab['ADULTS']= df4_Lab['ADULTS'].replace(3, 99)\n",
        "df4_Lab['ADULTS']= df4_Lab['ADULTS'].replace(4, 99)\n",
        "df4_Lab['ADULTS']= df4_Lab['ADULTS'].replace(1, 99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQQND2hQcXg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'ADULTS')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lonLJSbDZcni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ajustes a serem feitos em df4:\n",
        "df4['ADULTS']= df4['ADULTS'].replace(9, 99)\n",
        "df4['ADULTS']= df4['ADULTS'].replace(0, 99)\n",
        "df4['ADULTS']= df4['ADULTS'].replace(8, 99)\n",
        "df4['ADULTS']= df4['ADULTS'].replace(7, 99)\n",
        "df4['ADULTS']= df4['ADULTS'].replace(6, 99)\n",
        "df4['ADULTS']= df4['ADULTS'].replace(5, 99)\n",
        "df4['ADULTS']= df4['ADULTS'].replace(3, 99)\n",
        "df4['ADULTS']= df4['ADULTS'].replace(4, 99)\n",
        "df4['ADULTS']= df4['ADULTS'].replace(1, 99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfeQIbVhqiFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qajGfRdAqiKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'DEVICE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS6_9_BaqiB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4_Lab['DEVICE']= df4_Lab['DEVICE'].replace('NO_DEVICE', 'OTHER')\n",
        "df4_Lab['DEVICE']= df4_Lab['DEVICE'].replace('TABLET', 'OTHER')\n",
        "df4_Lab['DEVICE']= df4_Lab['DEVICE'].replace('COMPUTER', 'OTHER')\n",
        "df4_Lab['DEVICE']= df4_Lab['DEVICE'].replace('SMARTPHONE', 'OTHER')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6YLPEQSa7-e",
        "colab_type": "text"
      },
      "source": [
        "Agrupamos todas as categorias da variável DEVICE e mesmo assim não conseguimos produzir algo com razoável poder preditivo. Portanto, vou excluir esta variável:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtDxTIhzqqz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df4.drop('DEVICE', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC8wzSoVswUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qhQ8NLAswdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'HAUL_TYPE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvWU4wkUswiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuGa15EnswRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'TRIP_TYPE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wVy_df9swM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4_Lab['TRIP_TYPE']= df4_Lab['TRIP_TYPE'].replace('ONE_WAY', 'OTHER')\n",
        "df4_Lab['TRIP_TYPE']= df4_Lab['TRIP_TYPE'].replace('ROUND_TRIP', 'OTHER')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkGNRjALs9rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4['TRIP_TYPE']= df4['TRIP_TYPE'].replace('ONE_WAY', 'OTHER')\n",
        "df4['TRIP_TYPE']= df4['TRIP_TYPE'].replace('ROUND_TRIP', 'OTHER')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEhc8usJdElq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwAOqL0ms98l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'COMPANY')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSOSQucQs95W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df4.drop('COMPANY', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NMX4Nc2dPME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42ZKfZDGs904",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'DISTANCE_BUCKET')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twWXkP5ts9yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AJUSTE MANUAL\n",
        "df4_Lab['DISTANCE_BUCKET']= df4_Lab['DISTANCE_BUCKET'].replace(2, 99)\n",
        "df4_Lab['DISTANCE_BUCKET']= df4_Lab['DISTANCE_BUCKET'].replace(10, 99)\n",
        "df4_Lab['DISTANCE_BUCKET']= df4_Lab['DISTANCE_BUCKET'].replace(8, 99)\n",
        "df4_Lab['DISTANCE_BUCKET']= df4_Lab['DISTANCE_BUCKET'].replace(7, 99)\n",
        "df4_Lab['DISTANCE_BUCKET']= df4_Lab['DISTANCE_BUCKET'].replace(9, 99)\n",
        "df4_Lab['DISTANCE_BUCKET']= df4_Lab['DISTANCE_BUCKET'].replace(1, 99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL7v0Xc0tXBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AJUSTE\n",
        "df4['DISTANCE_BUCKET']= df4['DISTANCE_BUCKET'].replace(2, 99)\n",
        "df4['DISTANCE_BUCKET']= df4['DISTANCE_BUCKET'].replace(10, 99)\n",
        "df4['DISTANCE_BUCKET']= df4['DISTANCE_BUCKET'].replace(8, 99)\n",
        "df4['DISTANCE_BUCKET']= df4['DISTANCE_BUCKET'].replace(7, 99)\n",
        "df4['DISTANCE_BUCKET']= df4['DISTANCE_BUCKET'].replace(9, 99)\n",
        "df4['DISTANCE_BUCKET']= df4['DISTANCE_BUCKET'].replace(1, 99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xks-K4Ljuk5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yDk1hEGuk2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'COUNTRY')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSNL9VkBukzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4_Lab['COUNTRY']= df4_Lab['COUNTRY'].replace('PL', 'OTHERS')\n",
        "df4_Lab['COUNTRY']= df4_Lab['COUNTRY'].replace('IN', 'OTHERS')\n",
        "df4_Lab['COUNTRY']= df4_Lab['COUNTRY'].replace('CL', 'OTHERS')\n",
        "df4_Lab['COUNTRY']= df4_Lab['COUNTRY'].replace('PE', 'OTHERS')\n",
        "df4_Lab['COUNTRY']= df4_Lab['COUNTRY'].replace('VE', 'OTHERS')\n",
        "df4_Lab['COUNTRY']= df4_Lab['COUNTRY'].replace('MX', 'OTHERS')\n",
        "df4_Lab['COUNTRY']= df4_Lab['COUNTRY'].replace('CA', 'OTHERS')\n",
        "df4_Lab['COUNTRY']= df4_Lab['COUNTRY'].replace('CO', 'OTHERS')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvbcovBEfZFA",
        "colab_type": "text"
      },
      "source": [
        "Observe que o IV score desta variável é 0.05 e esse valor não vai mudar se agruparmos todas as categorias da variável COUNTRY. Portanto, é uma variável com nenhum poder preditivo. Decidi excluir esta variável."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72JYwByhukmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df4.drop('COUNTRY', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg2oolI4fxMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA3a0it0fxHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'GDS')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MtmxOjNfxCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4_Lab['GDS']= df4_Lab['GDS'].replace(4, 99)\n",
        "df4_Lab['GDS']= df4_Lab['GDS'].replace(3, 99)\n",
        "df4_Lab['GDS']= df4_Lab['GDS'].replace(2, 99)\n",
        "\n",
        "df4_Lab['GDS']= df4_Lab['GDS'].replace(1, 99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM_8Nw2qfw9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ajuste definitivo\n",
        "df4['GDS']= df4['GDS'].replace(4, 99)\n",
        "df4['GDS']= df4['GDS'].replace(3, 99)\n",
        "df4['GDS']= df4['GDS'].replace(2, 99)\n",
        "\n",
        "df4['GDS']= df4['GDS'].replace(1, 99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjKsulxLgmQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IZnBwkhgmfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'TRAIN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB5H_iXoguvt",
        "colab_type": "text"
      },
      "source": [
        "Baixissimo PP para a variável TRAIN. Decidi excluí-la."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfFv67KOgmMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df4.drop('TRAIN', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxmJM-FWg8Cg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG3Or04Xg8aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'CHILDREN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVjoMagVhFiW",
        "colab_type": "text"
      },
      "source": [
        "Baiximo PP para a variável CHILDREN. Decidi excluí-la. Perceba que estamos excluindo variável importantes que ajudam definir se alguém vai ou não comprar uma mala adicional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z4C4mieg79r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df4.drop('CHILDREN', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puktZBwPhUbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-EwPW2hUYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'INFANTS')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goq4sagdhhp1",
        "colab_type": "text"
      },
      "source": [
        "0 de PP para a variável INFANTS. Vou exluir esta variável."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEPJRqAihUTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df4.drop('INFANTS', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woQr4UP9g743",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW0Yoz_YhusE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'NO_GDS')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up0l_eTPh0oX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ajuste manual\n",
        "df4_Lab['NO_GDS']= df4_Lab['NO_GDS'].replace(4, 99)\n",
        "df4_Lab['NO_GDS']= df4_Lab['NO_GDS'].replace(3, 99)\n",
        "df4_Lab['NO_GDS']= df4_Lab['NO_GDS'].replace(2, 99)\n",
        "\n",
        "df4_Lab['NO_GDS']= df4_Lab['NO_GDS'].replace(1, 99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytf7jZroh1BL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ajuste definitivo\n",
        "df4['NO_GDS']= df4['NO_GDS'].replace(4, 99)\n",
        "df4['NO_GDS']= df4['NO_GDS'].replace(3, 99)\n",
        "df4['NO_GDS']= df4['NO_GDS'].replace(2, 99)\n",
        "\n",
        "df4['NO_GDS']= df4['NO_GDS'].replace(1, 99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW0FELqnh1TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGRWKahio7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'MONTH_DEPARTURE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGN5mh6JjpRa",
        "colab_type": "text"
      },
      "source": [
        "Baixíssimo PP para a variável MONTH_DEPARTURE. Decidi excluir esta variável."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U49RIWnbjv8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df4.drop('MONTH_DEPARTURE', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii5-VFW1j6c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qNZ8bruj6sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Calcula_Predictive_Power(df4_Lab, 'TRIP_TYPE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJfgPbpkj2Ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BknNArv1eyBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df6= df4.copy()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df6= pd.get_dummies(data=df6, columns=['ADULTS','GDS', 'NO_GDS','HAUL_TYPE', 'TRIP_TYPE', 'DISTANCE_BUCKET'])\n",
        "\n",
        "#df6['DEVICE']= LabelEncoder().fit_transform(df6['DEVICE'])\n",
        "#df6['HAUL_TYPE']= LabelEncoder().fit_transform(df6['HAUL_TYPE'])\n",
        "#df6['PRODUCT']= LabelEncoder().fit_transform(df6['PRODUCT'])\n",
        "#df6['TRIP_TYPE']= LabelEncoder().fit_transform(df6['TRIP_TYPE'])\n",
        "#df6['COMPANY']= LabelEncoder().fit_transform(df6['COMPANY'])\n",
        "#df6['COUNTRY']= LabelEncoder().fit_transform(df6['COUNTRY'])\n",
        "#df6['DISTANCE_BUCKET']= LabelEncoder().fit_transform(df6['DISTANCE_BUCKET'])\n",
        "df6.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbFDWd_JEZw",
        "colab_type": "text"
      },
      "source": [
        "## Treating categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGzOYgPYMv6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for col in l_Vars_Obj:\n",
        "#    df11[col]= LabelEncoder().fit_transform(df11[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IoUBan0QJWW",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwJtOjFmQOUy",
        "colab_type": "text"
      },
      "source": [
        "## Train/Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk_vdqSq6qD-",
        "colab_type": "text"
      },
      "source": [
        "### Balancing the training sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgDzwv35xmn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBahHsJwvKc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X= df6.iloc[train_index, :]\n",
        "y= X[['EXTRA_BAGGAGE']].astype(int)\n",
        "X= X.drop('EXTRA_BAGGAGE', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYnIQwlsZLGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)\n",
        "\n",
        "i_Seed= 20111974\n",
        "i_CV= 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmE-ycLi73_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying RandomUnderSampler\n",
        "X_Resampled0, y_Resampled0 = RandomUnderSampler().fit_resample(X_train, y_train)\n",
        "#print(sorted(Counter(y_Resampled0).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sapCUva7Y3Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_C = np.ravel(y_test, order='C')\n",
        "y_train_C = np.ravel(y_train, order='C')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdSoEGznOXKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying SMOTE to our data and checking the class counts\n",
        "X_Resampled1, y_Resampled1 = SMOTE().fit_resample(X_train, y_train_C)\n",
        "#print(sorted(Counter(y_Resampled1).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOmLKRJLZIGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying ADASYN\n",
        "X_Resampled2, y_Resampled2 = ADASYN().fit_resample(X_train, y_train_C)\n",
        "#print(sorted(Counter(y_Resampled2).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qeibTMgZRGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BorderlineSMOTE\n",
        "X_Resampled3, y_Resampled3 = BorderlineSMOTE().fit_resample(X_train, y_train_C)\n",
        "#print(sorted(Counter(y_Resampled3).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSkWEZo_fndk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports \n",
        "X_Resampled4, y_Resampled4 = RandomOverSampler().fit_resample(X_train, y_train_C)\n",
        "#print(sorted(Counter(y_Resampled4).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS6jPT2q2LvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um6eDoo5cfGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(X_Resampled0, y_Resampled0, test_size= 0.1, stratify= y_Resampled0, )\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_Resampled1, y_Resampled1, test_size= 0.1, stratify= y_Resampled1)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_Resampled2, y_Resampled2, test_size= 0.1, stratify= y_Resampled2)\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_Resampled3, y_Resampled3, test_size= 0.1, stratify= y_Resampled3)\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X_Resampled4, y_Resampled4, test_size= 0.1, stratify= y_Resampled4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGvmZ07J6j_H",
        "colab_type": "text"
      },
      "source": [
        "Next, we will apply the following estimators / classifiers to the training sample:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6alHA0z9cHe",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNO3IhZO905D",
        "colab_type": "text"
      },
      "source": [
        "## Interpretation\n",
        "> A good F1 score means that you have low false positives and low false negatives, so you’re correctly identifying real threats and you are not disturbed by false alarms. \n",
        ">> An F1 score is considered perfect when it’s 1, while the model is a total failure when it’s 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kYW_yzqvNdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import f1_score, accuracy_score, average_precision_score, confusion_matrix, precision_score, recall_score, log_loss, cohen_kappa_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAGezEXE-ljX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=False,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize= (8,8),\n",
        "                          cmap='Blues'):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5k__EnD7tGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definindo a função para o GridSearchCV\n",
        "def GridSearchOptimizer(modelo, d_Parametros, X_train, y_train, X_test, y_test, cv= i_CV):\n",
        "    Model_GridSearchCV = GridSearchCV(modelo, d_Parametros, cv= i_CV, n_jobs= -1, verbose= 10, scoring= 'f1')\n",
        "    Model_GridSearchCV.fit(X_train, y_train)\n",
        "    \n",
        "    # Parâmetros que otimizam a classificação:\n",
        "    print(f'\\nParametros otimizados: {Model_GridSearchCV.best_params_}')\n",
        "    \n",
        "    Model_Opt= XGBoostingClassifier(learning_rate= Model_GridSearchCV.best_params_['learning_rate'],\n",
        "                                        max_depth= Model_GridSearchCV.best_params_['max_depth'],\n",
        "                                        subsample= Model_GridSearchCV.best_params_['subsample'],\n",
        "                                        gamma= Model_GridSearchCV.best_params_['gamma'],\n",
        "                                        reg_lambda= Model_GridSearchCV.best_params_['reg_lambda'],\n",
        "                                        reg_alpha= Model_GridSearchCV.best_params_['reg_alpha'],\n",
        "                                        n_estimators= Model_GridSearchCV.best_params_['n_estimators'],\n",
        "                                        min_child_weight= Model_GridSearchCV.best_params_['min_child_weight'])\n",
        "       \n",
        "    # Treina novamente usando os parametros otimizados...\n",
        "    Model_Opt.fit(X_train, y_train)\n",
        "\n",
        "    # Cross-Validation com 10 folds\n",
        "    print(f'\\n********* CROSS-VALIDATION ***********')\n",
        "    a_Scores_CV = cross_val_score(Model_Opt, X_train, y_train, cv= i_CV)\n",
        "    print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV.mean(),4)}')\n",
        "    print(f'std médio das Acurácias calculadas pelo CV: {100*round(a_Scores_CV.std(),4)}')\n",
        "\n",
        "    # Faz predições com os parametros otimizados...\n",
        "    y_pred = Model_Opt.predict(X_test)\n",
        "  \n",
        "    # Importância das COLUNAS\n",
        "    print(f'\\n********* IMPORTÂNCIA DAS COLUNAS ***********')\n",
        "    df_Importance= pd.DataFrame(zip(l_Col_Names, Model_Opt.feature_importances_), columns= ['coluna', 'importancia'])\n",
        "    df_Importance= df_Importance.sort_values(by= ['importancia'], ascending=False)\n",
        "    print(df_Importance)\n",
        "\n",
        "    # Matriz de Confusão\n",
        "    print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    cf_labels = ['True Neg','False Pos','False Neg','True Pos']\n",
        "    cf_categories = ['Zero', 'One']\n",
        "    make_confusion_matrix(cf_matrix, group_names= cf_labels, categories= cf_categories)\n",
        "\n",
        "    return Model_Opt, Model_GridSearchCV.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GccQLum7M8NN",
        "colab_type": "text"
      },
      "source": [
        "# XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2EknshxXcGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Instancia...\n",
        "Model_XGB= XGBClassifier(learning_rate=0.01,  \n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      max_depth= 3, min_child_weight= 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w73GwNq4tPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_f1(cutoff):\n",
        "    def f1_cutoff(clf, X, y):\n",
        "        y_pred= cutoff_predict(clf, cutoff)\n",
        "        return sklearn.metrics.f1_score(y_pred, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_-bsSbZVgvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_CV= 3\n",
        "\n",
        "l_Scores= []\n",
        "l_Scores0= []\n",
        "l_Scores1= []\n",
        "l_Scores2= []\n",
        "l_Scores3= []\n",
        "l_Scores4= []\n",
        "f1_Score= []\n",
        "\n",
        "for cutoff in np.arange(0.1, 0.95, 0.1):\n",
        "    Model_XGB= XGBClassifier(learning_rate=0.01,  \n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      max_depth= 3, min_child_weight= 2)\n",
        "    \n",
        "    a_Scores_CV=  cross_val_score(Model_XGB, X_train, y_train, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV0= cross_val_score(Model_XGB, X_train0, y_train0, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV1= cross_val_score(Model_XGB, X_train1, y_train1, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV2= cross_val_score(Model_XGB, X_train2, y_train2, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV3= cross_val_score(Model_XGB, X_train3, y_train3, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "    a_Scores_CV4= cross_val_score(Model_XGB, X_train4, y_train4, cv= i_CV, scoring= custom_f1(cutoff))\n",
        "\n",
        "    l_Scores.append(a_Scores_CV)\n",
        "    l_Scores0.append(a_Scores_CV0)\n",
        "    l_Scores1.append(a_Scores_CV1)\n",
        "    l_Scores2.append(a_Scores_CV2)\n",
        "    l_Scores3.append(a_Scores_CV3)\n",
        "    l_Scores4.append(a_Scores_CV4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfFch2xpAY9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV.mean(),4)}; std médio das Acurácias calculadas pelo CV: {100*round(a_Scores_CV.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV0.mean(),4)}; std médio das Acurácias calculadas pelo CV0: {100*round(a_Scores_CV0.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV1.mean(),4)}; std médio das Acurácias calculadas pelo CV1: {100*round(a_Scores_CV1.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV2.mean(),4)}; std médio das Acurácias calculadas pelo CV2: {100*round(a_Scores_CV2.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV3.mean(),4)}; std médio das Acurácias calculadas pelo CV3: {100*round(a_Scores_CV3.std(),4)}')\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV4.mean(),4)}; std médio das Acurácias calculadas pelo CV4: {100*round(a_Scores_CV4.std(),4)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aadd4m99hBFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3ScO_kQFkZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def Mostra_Resultado(X_train_f, y_train_f, X_test_f, y_test_f):\n",
        "    #Model_f= XGBClassifier(learning_rate=0.01,  \n",
        "    #                  subsample = 0.8,\n",
        "    #                  objective='binary:logistic', \n",
        "    #                  max_depth= 3, min_child_weight= 2)\n",
        "\n",
        "    Model_f= RandomForestClassifier(n_estimators= 100, criterion= 'gini', min_samples_split= 3)\n",
        "    \n",
        "    Model_f.fit(X_train_f, y_train_f)\n",
        "    y_pred_f=  Model_f.predict(X_test_f)\n",
        "    results = confusion_matrix(y_test_f, y_pred_f)\n",
        "    print(results)\n",
        "    print(f'Accuracy Score : {accuracy_score(y_test_f, y_pred_f)}') \n",
        "    print(classification_report(y_test_f, y_pred_f))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7HaTTdEL_DK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train, y_train_C, X_test, y_test_C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1xQ2QkbMGsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train0_C = np.ravel(y_train0, order='C')\n",
        "y_test0_C = np.ravel(y_test0, order='C')\n",
        "\n",
        "Mostra_Resultado(X_train0, y_train0_C, X_test0, y_test0_C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn4l9sAgMIZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train1, y_train1, X_test1, y_test1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_cGvb6XMIju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train2, y_train2, X_test2, y_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdms8mnkMIpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train3, y_train3, X_test3, y_test3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNTdaoiMMIv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mostra_Resultado(X_train4, y_train4, X_test4, y_test4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIintw5gMIgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvdSbFiFNLCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dicionário de parâmetros para XGBoost:\n",
        "d_Parametros_XGB = {'min_child_weight': [1,3,5,7],\n",
        "                    'n_estimators': [100,250,500,1000],\n",
        "                    'subsample': [0.2, 0.4, 0.5, 0.6, 0.7],\n",
        "                    'max_depth': [2,4,7,10],\n",
        "                    'learning_rate': [0.1, 0.01, 0.001]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PykqgO4qV3kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Invoca a função\n",
        "Model_XGB, best_params= GridSearchOptimizer(Model_XGB, d_Parametros_XGB, X_train0, y_train0, X_test0, y_test0, cv= i_CV)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}