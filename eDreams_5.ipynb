{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled23.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/eDreams/blob/master/eDreams_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17LuXi1voKCf",
        "colab_type": "text"
      },
      "source": [
        "# Install & Load Main Python libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgBiQdX-a8wy",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/a-deep-dive-into-imbalanced-data-over-sampling-f1167ed74b5\n",
        "\n",
        "https://towardsdatascience.com/from-zero-to-hero-in-xgboost-tuning-e48b59bfaf58\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/xgboost-in-python\n",
        "\n",
        "https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
        "\n",
        "https://towardsdatascience.com/probability-calibration-for-imbalanced-dataset-64af3730eaab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIMVpjquns-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhymf5HmfuyW",
        "colab_type": "text"
      },
      "source": [
        "# Load dataframes: training & test sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWfL-XJFnZIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_train= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/train.csv?token=AGDJQ6YO3T3X2CYDGGUPRO252KACE\"\n",
        "url_test= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/test.csv?token=AGDJQ623H4TWE2QKQWENGA252KAD6\"\n",
        "\n",
        "# Stacking training and validation samples for a single treatment\n",
        "df_train= pd.read_csv(url_train, sep= \";\", index_col= 'ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "df_test= pd.read_csv(url_test, sep= \";\", index_col= 'ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "\n",
        "# Resetting the test sample indices\n",
        "df_test['ID']= range(50000, 80000)\n",
        "df_test.set_index('ID',inplace=True)\n",
        "\n",
        "# merge train and test\n",
        "df = df_train.append(df_test, sort= True)\n",
        "\n",
        "# Records training and test dataframe indexes to separate these dataframes later\n",
        "train_index = df_train.index\n",
        "test_index = df_test.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EItCRxK9OWVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbkvqUL-PMmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDIkBDEaP_eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puYrD8S-QnuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpAcrYpUQEL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWPMAIX1vMuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDANOjiKf4Qh",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrH6yLyI_LIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T= df.copy()\n",
        "# Capturing the Company: First 2 positions of WEBSITE.\n",
        "df_T['COMPANY']= df_T['WEBSITE'].str[0:2].astype(str)\n",
        "\n",
        "# Capturing the Country: rest of the string of WEBSITE.\n",
        "df_T['COUNTRY']= df_T['WEBSITE'].str[2:len(df['WEBSITE'])].astype(str)\n",
        "\n",
        "df_T.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbiq3bb5BFOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COMPANY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL2tFUwhBdwB",
        "colab_type": "text"
      },
      "source": [
        "There's no 'TL'. So I'll replace 'TL' by 'MV'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Wf9MUqBsof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COMPANY']= df_T['COMPANY'].replace('TL', 'MV')\n",
        "df_T['COMPANY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyo-zI5aAz62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE3dyQM56HBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Corrigindo Poland Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'PLC': 'PL'})\n",
        "\n",
        "# Corrigindo France Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'FRC': 'FR'})\n",
        "\n",
        "# Corrigindo DEC Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'DEC': 'DE'})\n",
        "\n",
        "# Corrigindo DEC Abbreviation\n",
        "df_T['COUNTRY']= df_T['COUNTRY'].replace({'DKC': 'DK'})\n",
        "\n",
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P86wEaspCljP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_T['COUNTRY']= df_T['COUNTRY'].replace(['PLC', 'DEC', 'DKC', 'FRC'], 'MV')\n",
        "#df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjGHXqYODAbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COUNTRY']= df_T['COUNTRY'].replace(['UK'], 'GB')\n",
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QRlW3cf6M5",
        "colab_type": "text"
      },
      "source": [
        "## Treating date variables\n",
        "> Since there is no information regarding the year of the transaction, I will assume that the transactions are from 2018 or 2019. I will assign the year conveniently from the analysis of the variables DEPARTURE and ARRIVAL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myZk676JnqrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2= df_T.copy()\n",
        "df2['DEPARTURE_WITH_YEAR']= df2['DEPARTURE'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR']= df2['ARRIVAL'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= df2['ARRIVAL'] +'/2019'\n",
        "\n",
        "df2['DEPARTURE_WITH_YEAR']= pd.to_datetime(df2['DEPARTURE_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR_FIXED'])\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPw1d6SgukXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2['MONTH_DEPARTURE']= df2['DEPARTURE_WITH_YEAR'].dt.month\n",
        "df2= df2.drop(['DEPARTURE_WITH_YEAR', 'ARRIVAL_WITH_YEAR', 'ARRIVAL_WITH_YEAR_FIXED', 'WEBSITE', 'DEPARTURE','ARRIVAL','TIMESTAMP'], axis= 1)\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKGY0hPj8uAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting column DISTANCE to numeric. For this purpose, I'll cut the distance in the \",\"\n",
        "df3= df2.copy()\n",
        "df3[['DISTANCE_2','DISTANCE_REST']] = df3['DISTANCE'].str.split(\",\",expand=True)\n",
        "df3['DISTANCE_2']= pd.to_numeric(df3['DISTANCE_2'])\n",
        "df3[['HAUL_TYPE','DISTANCE','DISTANCE_2','DISTANCE_REST']].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ2buWxxBEGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3= df3.drop(columns= ['DISTANCE_REST','DISTANCE'], axis= 1)\n",
        "df3= df3.rename({'DISTANCE_2': 'DISTANCE'}, axis=1)\n",
        "df3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1adzZo47EwjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking Missing Values\n",
        "df3.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaAjeTcnH24a",
        "colab_type": "text"
      },
      "source": [
        "Let's treat Missing Values in DISTANCE and DEVICE below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFerujs2OUYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing NaN's from DISTANCE\n",
        "df3['DISTANCE'] = np.where((df3['DISTANCE'].isnull()), df3['DISTANCE'].median(), df3['DISTANCE'])\n",
        "\n",
        "# Replacing NaN's of DEVICE with 'NO_DEVICE'\n",
        "df3[\"DEVICE\"].fillna(\"NO_DEVICE\", inplace= True)\n",
        "\n",
        "df3.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5nGTv5SF-JA",
        "colab_type": "text"
      },
      "source": [
        "# Binning numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpkwv3XC5lkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBGPZOyO3taE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df3.copy()\n",
        "df4['DISTANCE_BUCKET'] = pd.cut(df4['DISTANCE'], bins= 10, labels= [1,2,3,4,5,6,7,8,9,10])\n",
        "df4= df4.drop(['DISTANCE'], axis= 1)\n",
        "df4['DISTANCE_BUCKET'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJxojEs-5Ou4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIf8bQdKGFbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df5= df4.copy()\n",
        "\n",
        "d_Var_Target= {True: 1, False: 0}\n",
        "df5['EXTRA_BAGGAGE']= df5['EXTRA_BAGGAGE'].map(d_Var_Target)\n",
        "df5['SMS']= df5['SMS'].map(d_Var_Target)\n",
        "df5['TRAIN']= df5['TRAIN'].map(d_Var_Target)\n",
        "df5.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4qh8wTIcAc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3OyF_RtcUXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp ./sample_data/FeatureTools.csv /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja4U0T7eql3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feature_matrix= df_train= pd.read_csv('/content/drive/My Drive/FeatureTools.csv', sep= \",\", index_col= 'ID')\n",
        "#feature_matrix.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igTzRbLbsCzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feature_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kro7VUfsHjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feature_matrix.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BknNArv1eyBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df6= feature_matrix.copy()\n",
        "df6= df5.copy()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df6['DEVICE']= LabelEncoder().fit_transform(df6['DEVICE'])\n",
        "df6['HAUL_TYPE']= LabelEncoder().fit_transform(df6['HAUL_TYPE'])\n",
        "df6['PRODUCT']= LabelEncoder().fit_transform(df6['PRODUCT'])\n",
        "df6['TRIP_TYPE']= LabelEncoder().fit_transform(df6['TRIP_TYPE'])\n",
        "df6['COMPANY']= LabelEncoder().fit_transform(df6['COMPANY'])\n",
        "df6['COUNTRY']= LabelEncoder().fit_transform(df6['COUNTRY'])\n",
        "df6['DISTANCE_BUCKET']= LabelEncoder().fit_transform(df6['DISTANCE_BUCKET'])\n",
        "\n",
        "#df6.reset_index('ID', inplace=True)\n",
        "df6.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbFDWd_JEZw",
        "colab_type": "text"
      },
      "source": [
        "## Treating categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xph3AArLwjcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_Vars_Obj= list(df6.select_dtypes(include=['category', 'object']).columns)\n",
        "l_Vars_Obj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGzOYgPYMv6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for col in l_Vars_Obj:\n",
        "#    df11[col]= LabelEncoder().fit_transform(df11[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IoUBan0QJWW",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwJtOjFmQOUy",
        "colab_type": "text"
      },
      "source": [
        "## Train/Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk_vdqSq6qD-",
        "colab_type": "text"
      },
      "source": [
        "### Balancing the training sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM0lsoJd68Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMZ8mAJY48V7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calibration(data, train_pop, target_pop, sampled_train_pop, sampled_target_pop):\n",
        "\n",
        "    df_Calibrated= ((data*(target_pop/train_pop)/(sampled_target_pop/sampled_train_pop))/(((1-data)*(1-target_pop/train_pop)/(1-sampled_target_pop/sampled_train_pop))+(data*(target_pop/train_pop)/(sampled_target_pop/sampled_train_pop))))\n",
        "\n",
        "    return calibrated_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT8K4RjI60ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sorted(Counter(df6['EXTRA_BAGGAGE']).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZGhELa46bbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df7= calibration(df6, 50000, 500, 10000, 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRATe57y4Xmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df11.to_csv('df11.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgDzwv35xmn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBahHsJwvKc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X= df6.loc[train_index, :]\n",
        "y= X.loc[:, 'EXTRA_BAGGAGE']\n",
        "\n",
        "X= X.drop('EXTRA_BAGGAGE', axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlMeQPcIN2MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhObop7nY8TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYnIQwlsZLGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdSoEGznOXKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying SMOTE to our data and checking the class counts\n",
        "X_Resampled1, y_Resampled1 = SMOTE().fit_resample(X_train, y_train)\n",
        "print(sorted(Counter(y_Resampled1).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOmLKRJLZIGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying ADASYN\n",
        "X_Resampled2, y_Resampled2 = ADASYN().fit_resample(X_train, y_train)\n",
        "print(sorted(Counter(y_Resampled2).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qeibTMgZRGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BorderlineSMOTE\n",
        "X_Resampled3, y_Resampled3 = BorderlineSMOTE().fit_resample(X_train, y_train)\n",
        "print(sorted(Counter(y_Resampled3).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSkWEZo_fndk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports \n",
        "X_Resampled4, y_Resampled4 = RandomOverSampler(random_state=0).fit_resample(X_train, y_train)\n",
        "print(sorted(Counter(y_Resampled4).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzs53H5k5hlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calibration(model_results, X_train.shape, 500, 10000, 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um6eDoo5cfGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_Resampled1, y_Resampled1, test_size= 0.2)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_Resampled2, y_Resampled2, test_size= 0.2)\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_Resampled3, y_Resampled3, test_size= 0.2)\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X_Resampled4, y_Resampled4, test_size= 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGvmZ07J6j_H",
        "colab_type": "text"
      },
      "source": [
        "Next, we will apply the following estimators / classifiers to the training sample:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6alHA0z9cHe",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "> As I'll submit a binary output, I need to use a F1-Score, as suggested in the challenge. Firstly, let's understand what's F1-Score metric:\n",
        "\n",
        "* **Precision**: When the model predicts positive, how often is it correct? A low precision can also indicate a large number of False Positives.\n",
        "\n",
        "    $Precision= \\frac{TruePositives}{TruePositive + FalsePositives}$\n",
        "\n",
        "* **Recall**: Recall is the number of True Positives divided by the number of True Positives and the number of False Negatives. Put another way it is the number of positive predictions divided by the number of positive class values in the test data. It is also called Sensitivity or the True Positive Rate. A low recall indicates many False Negatives.\n",
        "\n",
        "    $Recall= \\frac{TruePositives}{TruePositives + FalseNegatives}$\n",
        "\n",
        "* **F1 Score**: F1 score conveys the balance between the precision and the recall.\n",
        "\n",
        "    $F1= 2*\\frac{Precision*Recall}{Precision+Recall}$\n",
        "\n",
        "Source: [Classification Accuracy is Not Enough: More Performance Measures You Can Use](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNO3IhZO905D",
        "colab_type": "text"
      },
      "source": [
        "## Interpretation\n",
        "> A good F1 score means that you have low false positives and low false negatives, so you’re correctly identifying real threats and you are not disturbed by false alarms. \n",
        ">> An F1 score is considered perfect when it’s 1, while the model is a total failure when it’s 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kYW_yzqvNdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "i_Seed= 20111974\n",
        "i_CV= 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAGezEXE-ljX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=False,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize= (8,8),\n",
        "                          cmap='Blues'):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5k__EnD7tGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definindo a função para o GridSearchCV\n",
        "def GridSearchOptimizer(modelo, Model_Opt, d_Parametros, X_train, y_train, X_test, y_test, cv= i_CV):\n",
        "    Model_GridSearchCV = GridSearchCV(modelo, d_Parametros, cv= i_CV, n_jobs= -1, verbose= 10, scoring= 'accuracy')\n",
        "    Model_GridSearchCV.fit(X_train, y_train)\n",
        "    #print(f\"\\nGridSearchCV levou {tempo_elapsed:.2f} segundos.\")\n",
        "\n",
        "    # Parâmetros que otimizam a classificação:\n",
        "    print(f'\\nParametros otimizados: {Model_GridSearchCV.best_params_}')\n",
        "    \n",
        "    if Model_Opt== 'Model_DT2':\n",
        "        print(f'\\nDecisionTreeClassifier *********************************************************************************************************')\n",
        "        Model_Opt= DecisionTreeClassifier(criterion= Model_GridSearchCV.best_params_['criterion'], \n",
        "                                          max_depth= Model_GridSearchCV.best_params_['max_depth'],\n",
        "                                          max_leaf_nodes= Model_GridSearchCV.best_params_['max_leaf_nodes'],\n",
        "                                          min_samples_split= Model_GridSearchCV.best_params_['min_samples_leaf'],\n",
        "                                          min_samples_leaf= Model_GridSearchCV.best_params_['min_samples_split'], \n",
        "                                          random_state= i_Seed)\n",
        "    elif Model_Opt== 'Model_RF2':\n",
        "        print(f'\\nRandomForestClassifier *********************************************************************************************************')\n",
        "        Model_Opt= RandomForestClassifier(bootstrap= Model_GridSearchCV.best_params_['bootstrap'],\n",
        "                                          max_depth= Model_GridSearchCV.best_params_['max_depth'],\n",
        "                                          max_features= Model_GridSearchCV.best_params_['max_features'],\n",
        "                                          min_samples_leaf= Model_GridSearchCV.best_params_['min_samples_leaf'],\n",
        "                                          min_samples_split= Model_GridSearchCV.best_params_['min_samples_split'],\n",
        "                                          n_estimators= Model_GridSearchCV.best_params_['n_estimators'],\n",
        "                                          random_state= i_Seed)\n",
        "        \n",
        "    elif Model_Opt== 'Model_AB2':\n",
        "        print(f'\\nAdaBoostClassifier *********************************************************************************************************')\n",
        "        Model_Opt= AdaBoostClassifier(algorithm='SAMME.R',\n",
        "                                      base_estimator=RandomForestClassifier(bootstrap= False, \n",
        "                                                                            max_depth= 10,\n",
        "                                                                            max_features= 'auto',\n",
        "                                                                            min_samples_leaf= 1, \n",
        "                                                                            min_samples_split= 2,\n",
        "                                                                            n_estimators= 400),\n",
        "                                      learning_rate= Model_GridSearchCV.best_params_['learning_rate'], \n",
        "                                      n_estimators= Model_GridSearchCV.best_params_['n_estimators'], \n",
        "                                      random_state=i_Seed)\n",
        "        \n",
        "    elif Model_Opt== 'Model_GB2':\n",
        "        print(f'\\nGradientBoostingClassifier *********************************************************************************************************')\n",
        "        Model_Opt= GradientBoostingClassifier(learning_rate= Model_GridSearchCV.best_params_['learning_rate'],\n",
        "                                              n_estimators= Model_GridSearchCV.best_params_['n_estimators'],\n",
        "                                              max_depth= Model_GridSearchCV.best_params_['max_depth'],\n",
        "                                              min_samples_split= Model_GridSearchCV.best_params_['min_samples_split'],\n",
        "                                              min_samples_leaf= Model_GridSearchCV.best_params_['min_samples_leaf'],\n",
        "                                              max_features= Model_GridSearchCV.best_params_['max_features'])\n",
        "        \n",
        "    elif Model_Opt== 'Model_XGB2':\n",
        "        print(f'\\nXGBoostingClassifier *********************************************************************************************************')\n",
        "        Model_Opt= XGBoostingClassifier(learning_rate= Model_GridSearchCV.best_params_['learning_rate'],\n",
        "                                        max_depth= Model_GridSearchCV.best_params_['max_depth'],\n",
        "                                        subsample= Model_GridSearchCV.best_params_['subsample'],\n",
        "                                        gamma= Model_GridSearchCV.best_params_['gamma'],\n",
        "                                        reg_lambda= Model_GridSearchCV.best_params_['reg_lambda'],\n",
        "                                        reg_alpha= Model_GridSearchCV.best_params_['reg_alpha'],\n",
        "                                        n_estimators= Model_GridSearchCV.best_params_['n_estimators'],\n",
        "                                        min_child_weight= Model_GridSearchCV.best_params_['min_child_weight'])\n",
        "\n",
        "                                        ': [1,3,5,7],\n",
        "                    '': [100,250,500,1000],\n",
        "                    '': [1, 1.5, 2, 3, 4.5],\n",
        "                    '': [0, 0.5, 1],\n",
        "                    '': [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
        "                    '': [0.2, 0.4, 0.5, 0.6, 0.7],\n",
        "                    'max_depth': [2,4,7,10],\n",
        "                    'learning_rate\n",
        "        \n",
        "    # Treina novamente usando os parametros otimizados...\n",
        "    Model_Opt.fit(X_train, y_train)\n",
        "\n",
        "    # Cross-Validation com 10 folds\n",
        "    print(f'\\n********* CROSS-VALIDATION ***********')\n",
        "    a_Scores_CV = cross_val_score(Model_Opt, X_train, y_train, cv= i_CV)\n",
        "    print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV.mean(),4)}')\n",
        "    print(f'std médio das Acurácias calculadas pelo CV: {100*round(a_Scores_CV.std(),4)}')\n",
        "\n",
        "    # Faz predições com os parametros otimizados...\n",
        "    y_pred = Model_Opt.predict(X_test)\n",
        "  \n",
        "    # Importância das COLUNAS\n",
        "    print(f'\\n********* IMPORTÂNCIA DAS COLUNAS ***********')\n",
        "    df_Importance= pd.DataFrame(zip(l_Col_Names, Model_Opt.feature_importances_), columns= ['coluna', 'importancia'])\n",
        "    df_Importance= df_Importance.sort_values(by= ['importancia'], ascending=False)\n",
        "    print(df_Importance)\n",
        "\n",
        "    # Matriz de Confusão\n",
        "    print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    cf_labels = ['True Neg','False Pos','False Neg','True Pos']\n",
        "    cf_categories = ['Zero', 'One']\n",
        "    make_confusion_matrix(cf_matrix, group_names= cf_labels, categories= cf_categories)\n",
        "\n",
        "    return Model_Opt, Model_GridSearchCV.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GccQLum7M8NN",
        "colab_type": "text"
      },
      "source": [
        "# XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2EknshxXcGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Instancia...\n",
        "Model_XGB= XGBClassifier(learning_rate=0.01,  \n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      max_depth= 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rn7w0C5-Xci8",
        "colab": {}
      },
      "source": [
        "Model_XGB.fit(X_train1, y_train1)\n",
        "y_pred1 = Model_XGB.predict(X_test1)\n",
        "accuracy_score(y_test1, y_pred1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GTEoiuT2XcjC",
        "colab": {}
      },
      "source": [
        "Model_XGB.fit(X_train2, y_train2)\n",
        "y_pred2 = Model_XGB.predict(X_test2)\n",
        "accuracy_score(y_test2, y_pred2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QPQIPlfnXcjF",
        "colab": {}
      },
      "source": [
        "Model_XGB.fit(X_train3, y_train3)\n",
        "y_pred3 = Model_XGB.predict(X_test3)\n",
        "accuracy_score(y_test3, y_pred3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_K3pdITKXcjH",
        "colab": {}
      },
      "source": [
        "Model_XGB.fit(X_train4, y_train4)\n",
        "y_pred4 = Model_XGB.predict(X_test4)\n",
        "accuracy_score(y_test4, y_pred4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKKBid2eE9wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate feature importances\n",
        "importances = Model_XGB.feature_importances_\n",
        "importances[0:45]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-hpfvTDKXQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Colunas mais importantes\n",
        "X2= X_train.iloc[:, [0,3,6,7,8,9,14,20,22,27,28]]\n",
        "X_test= X_test.iloc[:, [0,3,6,7,8,9,14,20,22,27,28]]\n",
        "l_Cols= X2.columns\n",
        "X2.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwuFPFD8fjnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZimlpIGXfOEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Resampled22, y_Resampled22 = BorderlineSMOTE().fit_resample(X2, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nPOUsrQhJi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Resampled22= pd.DataFrame(X_Resampled22, columns= [X2.columns])\n",
        "y_Resampled22= pd.DataFrame(y_Resampled22)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItrpRxkGfrJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Model_XGB.fit(X_Resampled22, y_Resampled22)\n",
        "y_pred = Model_XGB.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOiC965-ND6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross-Validation com 10 folds\n",
        "a_Scores_CV = cross_val_score(Model_XGB, X_train22, y_train2, cv= i_CV)\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_Scores_CV.mean(),4)}')\n",
        "print(f'std médio das Acurácias calculadas pelo CV: {100*round(a_Scores_CV.std(),4)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvdSbFiFNLCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dicionário de parâmetros para XGBoost:\n",
        "d_Parametros_XGB = {'min_child_weight': [1,3,5,7],\n",
        "                    'n_estimators': [100,250,500,1000],\n",
        "                    'reg_lambda': [1, 1.5, 2, 3, 4.5],\n",
        "                    'reg_alpha': [0, 0.5, 1],\n",
        "                    'gamma': [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
        "                    'subsample': [0.2, 0.4, 0.5, 0.6, 0.7],\n",
        "                    'max_depth': [2,4,7,10],\n",
        "                    'learning_rate': [0.1, 0.01, 0.001]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PykqgO4qV3kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Invoca a função\n",
        "Model_XGB, best_params= GridSearchOptimizer(Model_XGB, 'Model_XGB2', d_Parametros_XGB, X_train, y_train, X_test, y_test, cv= i_CV)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXR4RShaNU-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Como o procedimento acima levou 372 minutos para executar, então vou estimar Model_XGB2 abaixo usando os parâmetros acima estimados\n",
        "best_params= {'colsample_bytree': 0.8, 'gamma': 0.5, 'learning_rate': 0.51, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6}\n",
        "\n",
        "Model_XGB2= XGBClassifier(min_child_weight= best_params['min_child_weight'],\n",
        "                          gamma= best_params['gamma'],\n",
        "                          subsample= best_params['subsample'],\n",
        "                          colsample_bytree= best_params['colsample_bytree'],\n",
        "                          max_depth= best_params['max_depth'],\n",
        "                          learning_rate= best_params['learning_rate'], \n",
        "                          random_state= i_Seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQekDqR7ncE2",
        "colab_type": "text"
      },
      "source": [
        "# Submitting my model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrL_MLi7n_EP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Val= df10[l_Vars][df10['EXTRA_BAGGAGE'].isna()]\n",
        "y_Val= df10[['EXTRA_BAGGAGE']][df10['EXTRA_BAGGAGE'].isna()]\n",
        "\n",
        "print(X_Val.shape, y_Val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHci3WoTlY5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Val['EXTRA_BAGGAGE'] = clf.predict(X_Val)\n",
        "y_pred_submission= X_Val[['EXTRA_BAGGAGE']]\n",
        "y_pred_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnjBBMglqfL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_submission['EXTRA_BAGGAGE']= y_pred_submission['EXTRA_BAGGAGE'].map({0.0: False, 1.0: True})\n",
        "y_pred_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1rxBI4toZ4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_submission.to_csv(r'eDreams_Submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}