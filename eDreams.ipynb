{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/eDreams/blob/master/eDreams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17LuXi1voKCf",
        "colab_type": "text"
      },
      "source": [
        "# Install & Load Main Python libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQy1h2RVoVxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bamboolib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIMVpjquns-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import bamboolib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhymf5HmfuyW",
        "colab_type": "text"
      },
      "source": [
        "# Load dataframes: training & test sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWfL-XJFnZIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_train= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/train.csv?token=AGDJQ67D2WENLE2YEMFJBPC5SHK26\"\n",
        "url_test= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/test.csv?token=AGDJQ6YYHJOGUATPKWUASIK5SSGF6\"\n",
        "\n",
        "# Stacking training and validation samples for a single treatment\n",
        "df_train= pd.read_csv(url_train, sep= \";\", index_col='ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "df_test= pd.read_csv(url_test, sep= \";\", index_col='ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "\n",
        "# Resetting the test sample indices\n",
        "df_test.index= range(50000, 80000)\n",
        "\n",
        "# merge train and test\n",
        "df = df_train.append(df_test, sort= True)\n",
        "\n",
        "# Records training and test dataframe indexes to separate these dataframes later\n",
        "train_index = df_train.index\n",
        "test_index = df_test.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EItCRxK9OWVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbkvqUL-PMmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDIkBDEaP_eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puYrD8S-QnuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpAcrYpUQEL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWPMAIX1vMuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDANOjiKf4Qh",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QRlW3cf6M5",
        "colab_type": "text"
      },
      "source": [
        "## Treating date variables\n",
        "> Since there is no information regarding the year of the transaction, I will assume that the transactions are from 2018 or 2019. I will assign the year conveniently from the analysis of the variables DEPARTURE and ARRIVAL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myZk676JnqrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2= df.copy()\n",
        "df2['DEPARTURE_WITH_YEAR']= df2['DEPARTURE'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR']= df2['ARRIVAL'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= df2['ARRIVAL'] +'/2019'\n",
        "\n",
        "df2['DEPARTURE_WITH_YEAR']= pd.to_datetime(df2['DEPARTURE_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR_FIXED'])\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haF1q_a0gKcu",
        "colab_type": "text"
      },
      "source": [
        "As we do not have year information, in some cases/rows we have ARRIVAL < DEPARTURE. Let's take a look in some cases where ARRIVAL < DEPARTURE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucsI7q6LhjEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3= df2.copy()\n",
        "\n",
        "# I created the variable IS_ARRIVAL_BEFORE_DEPARTURE to help us identify when ARRIVAL < DEPARTURE:\n",
        "df3['IS_ARRIVAL_BEFORE_DEPARTURE']= df3['ARRIVAL_WITH_YEAR']<df3['DEPARTURE_WITH_YEAR']\n",
        "\n",
        "# Fixing cases when ARRIVAL < DEPARTURE\n",
        "df3.loc[df3['IS_ARRIVAL_BEFORE_DEPARTURE']== True, 'ARRIVAL_WITH_YEAR']= df3['ARRIVAL_WITH_YEAR_FIXED']\n",
        "df3[['ARRIVAL', 'DEPARTURE', 'DEPARTURE_WITH_YEAR', 'ARRIVAL_WITH_YEAR']][df3['IS_ARRIVAL_BEFORE_DEPARTURE']== True].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGfnRkrniBH3",
        "colab_type": "text"
      },
      "source": [
        "> Take for example line 15 (output above):\n",
        "* DEPARTURE= December 15th;\n",
        "* ARRIVAL= January 29th.\n",
        "\n",
        "> Without information for the year, then ARRIVAL < DEPARTURE. However, look at the variables DEPARTURE_WITH_YEAR and ARRIVAL_WITH_YEAR above:\n",
        "* DEPARTURE_WITH_YEAR= December 15th of 2018;\n",
        "* ARRIVAL_WITH_YEAR= January 29th of 2019.\n",
        "\n",
        "In this case, we fixed the problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtS019CfldHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop the unnecessary variables:\n",
        "df3= df3.drop(columns= ['DEPARTURE', 'ARRIVAL', 'ARRIVAL_WITH_YEAR_FIXED'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MknGmW_lGIz",
        "colab_type": "text"
      },
      "source": [
        "Next, we calculate the variable ARRIVAL_DEPARTURE = ARRIVAL_WITH_YEAR - DEPARTURE_WITH_YEAR:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ohReuC6Px3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the variable ARRIVAL_DEPARTURE:\n",
        "df3['ARRIVAL_DEPARTURE']= (df3['ARRIVAL_WITH_YEAR']-df3['DEPARTURE_WITH_YEAR']).dt.days.astype(int)\n",
        "\n",
        "# Show some cases:\n",
        "df3[['DEPARTURE_WITH_YEAR', 'ARRIVAL_WITH_YEAR', 'ARRIVAL_DEPARTURE']].head() #[df3['IS_ARRIVAL_BEFORE_DEPARTURE']== True].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb7YWHbtdvV-",
        "colab_type": "text"
      },
      "source": [
        "> Something strange with the variable ARRIVAL_DEPARTURE. Take a look at the line 2 (above). We have:\n",
        "* DEPARTURE_WITH_YEAR= 2018-07-29\n",
        "* ARRIVAL_WITH_YEAR= 2018-08-19\n",
        "\n",
        "It is 21 days between DEPARTURE and ARRIVAL!\n",
        "\n",
        "Let's take a look in some statistics below. For example, let's look at the proportion of cases where ARRIVAL_DEPARTURE > 5. I am using 5 as an example, but I consider 5 a long time between departure and arrival."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDdSaImBoOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3_Zoom= df3[df3['ARRIVAL_DEPARTURE'] > 5]\n",
        "df3_Zoom.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TAukV-OpJ9s",
        "colab_type": "text"
      },
      "source": [
        "Strangely, many cases over 5 days. \n",
        "\n",
        "Below, I present the distribution of the ARRIVAL_DEPARTURE variable. As we can see, there are cases older than 50 days!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfyphUD8ecHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(df3['ARRIVAL_DEPARTURE'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bp0-Ym9fENa",
        "colab_type": "text"
      },
      "source": [
        "Below I present some descriptive statistics for ARRIVAL_DEPARTURE. The median of the variable by type of HAUL_TYPE makes more sense. However, I still find median= 10 a long time in the case of HAUL_TYPE= \"INTERCONTINENTAL\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3HxlKdCdxUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3.groupby('HAUL_TYPE').agg({'ARRIVAL_DEPARTURE': ['min', 'median', 'mean', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZZpOTs8qpeW",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the Boxplot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8M4TUXJfDDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcdefaults()\n",
        "sns.catplot(y='ARRIVAL_DEPARTURE', kind=\"box\", data=df3, height=4, aspect=1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CusxUGlNrSgT",
        "colab_type": "text"
      },
      "source": [
        "Below, the boxplot of ARRIVAL_DEPARTURE by HAUL_TYPE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2pJgkcPebhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make boxplot with Catplot\n",
        "plt.rcdefaults()\n",
        "sns.catplot(x='HAUL_TYPE', y='ARRIVAL_DEPARTURE', kind=\"box\", data=df3, height=4, aspect=1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs8BjMOKq69r",
        "colab_type": "text"
      },
      "source": [
        "I will do the following, I will calculate the median disregarding the outliers of the variable ARRIVAL_DEPARTURE by HAUL_TYPE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3o_-3F5rbwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4= df3.copy()\n",
        "df_DOMESTIC= df4[['HAUL_TYPE', 'ARRIVAL_DEPARTURE']][df4['HAUL_TYPE']== 'DOMESTIC']\n",
        "df_CONTINENTAL= df4[['HAUL_TYPE', 'ARRIVAL_DEPARTURE']][df4['HAUL_TYPE']== 'CONTINENTAL']\n",
        "df_INTERCONTINENTAL= df4[['HAUL_TYPE', 'ARRIVAL_DEPARTURE']][df4['HAUL_TYPE']== 'INTERCONTINENTAL']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxGO6dngvWd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's take a look at one of it: df_DOMESTIC:\n",
        "df_DOMESTIC.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWh7qJmLuDF-",
        "colab_type": "text"
      },
      "source": [
        "Function to detect Outliers based on IQR-Score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKDDxJ2grbuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that identify outlier using IQR-Score:\n",
        "def IQR_Score_Outlier_Detect(column):\n",
        "    global df_Temp\n",
        "    \n",
        "    Q1 = df_Temp[column].quantile(0.25)\n",
        "    Q3 = df_Temp[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    df_Temp = df_Temp[~((df_Temp[column] < (Q1-1.5*IQR)) |(df_Temp[column] > (Q3+1.5*IQR)))]   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckj7CwK7u38Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Temp= df_DOMESTIC\n",
        "IQR_Score_Outlier_Detect('ARRIVAL_DEPARTURE')\n",
        "df_Temp.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1rpHMB2rbqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make boxplot with Catplot\n",
        "plt.rcdefaults()\n",
        "sns.catplot(y='ARRIVAL_DEPARTURE', kind=\"box\", data=df_Temp, height=4, aspect= 1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UnhS6bo4S1g",
        "colab_type": "text"
      },
      "source": [
        "As you can see above, we removed the outliers from the dataframe when HAUL_TYPE= \"DOMESTIC\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu68ClSuyQzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Temp.groupby('HAUL_TYPE').agg({'ARRIVAL_DEPARTURE': ['min', 'median', 'mean', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTUGp-Mu1grv",
        "colab_type": "text"
      },
      "source": [
        "In the case of HAUL_TYPE = 'DOMESTIC', we now have median = 1, according to the IQR-Score criteria. Let's see how the other cases look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJP1oxTqynqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Temp= df_CONTINENTAL\n",
        "IQR_Score_Outlier_Detect('ARRIVAL_DEPARTURE')\n",
        "df_Temp.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHYq5eOkynlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make boxplot with Catplot\n",
        "plt.rcdefaults()\n",
        "sns.catplot(y='ARRIVAL_DEPARTURE', kind=\"box\", data=df_Temp, height=4, aspect= 1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aanxut9J4hPm",
        "colab_type": "text"
      },
      "source": [
        "As you can see above, we removed the outliers from the dataframe when HAUL_TYPE= \"CONTINENTAL\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ9GCUptyngz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Temp.groupby('HAUL_TYPE').agg({'ARRIVAL_DEPARTURE': ['min', 'median', 'mean', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS5nxlhg2BX1",
        "colab_type": "text"
      },
      "source": [
        "In the case of HAUL_TYPE = \"CONTINENTAL\", we have median = 3. Before it was 3, but the average has reduced a lot. Finally, let's look at the last class: HAUL_TYPE = \"INTERCONTINENTAL\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CYYrKOn2XZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Temp= df_INTERCONTINENTAL\n",
        "IQR_Score_Outlier_Detect('ARRIVAL_DEPARTURE')\n",
        "df_Temp.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsA0X0sK2XXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make boxplot with Catplot\n",
        "plt.rcdefaults()\n",
        "sns.catplot(y='ARRIVAL_DEPARTURE', kind=\"box\", data=df_Temp, height=4, aspect= 1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXMyQRoU4rhe",
        "colab_type": "text"
      },
      "source": [
        "As you can see above, we removed the outliers from the dataframe when HAUL_TYPE= \"INTERCONTINENTAL\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzU3q6_Z2XUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Temp.groupby('HAUL_TYPE').agg({'ARRIVAL_DEPARTURE': ['min', 'median', 'mean', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwcWqTaS2lp3",
        "colab_type": "text"
      },
      "source": [
        "Finally, we have median = 9 for HAUL_TYPE = \"INTERCONTINENTAL\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmB1l9x-2wz-",
        "colab_type": "text"
      },
      "source": [
        "> **DECISION**: As I said earlier, I find the behavior of this variable strange. I initially considered deleting this variable, but now I've decided to keep it in the analysis. However, I will do the following transformation:\n",
        "* HAUL_TYPE = \"DOMESTIC\": If ARRIVAL_DEPARTURE> Median then ARRIVAL_DEPARTURE = Median;\n",
        "* HAUL_TYPE = \"CONTINENTAL\": If ARRIVAL_DEPARTURE> Median then ARRIVAL_DEPARTURE = Median;\n",
        "* HAUL_TYPE = \"INTERCONTINENTAL\": If ARRIVAL_DEPARTURE> Median then ARRIVAL_DEPARTURE = Median;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc0N60Oa5NPA",
        "colab_type": "text"
      },
      "source": [
        "Replacing all values of where ARRIVAL_DEPARTURE > Median:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx0bkim02lGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df5= df4.copy()\n",
        "#df5['ARRIVAL_DEPARTURE'].loc[((df5['ARRIVAL_DEPARTURE'] > 1) & (df5['HAUL_TYPE']== 'DOMESTIC'))] = 1\n",
        "#df5['ARRIVAL_DEPARTURE'].loc[((df5['ARRIVAL_DEPARTURE'] > 3) & (df5['HAUL_TYPE']== 'CONTINENTAL'))] = 3\n",
        "#df5['ARRIVAL_DEPARTURE'].loc[((df5['ARRIVAL_DEPARTURE'] > 9) & (df5['HAUL_TYPE']== 'INTERCONTINENTAL'))] = 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uggTU3VC7fNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df5= df4.copy()\n",
        "df5['ARRIVAL_DEPARTURE'] = np.where(((df5['ARRIVAL_DEPARTURE'] > 1) & (df5['HAUL_TYPE']== 'DOMESTIC')), 1, df5['ARRIVAL_DEPARTURE'])\n",
        "df5['ARRIVAL_DEPARTURE'] = np.where(((df5['ARRIVAL_DEPARTURE'] > 3) & (df5['HAUL_TYPE']== 'CONTINENTAL')), 3, df5['ARRIVAL_DEPARTURE'])\n",
        "df5['ARRIVAL_DEPARTURE'] = np.where(((df5['ARRIVAL_DEPARTURE'] > 9) & (df5['HAUL_TYPE']== 'INTERCONTINENTAL')), 9, df5['ARRIVAL_DEPARTURE'])\n",
        "\n",
        "# Checking statistics:\n",
        "df5.groupby('HAUL_TYPE').agg({'ARRIVAL_DEPARTURE': ['min', 'median', 'mean', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbPm5WFu2lEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df5.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MecuYMd_c53G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deleting Unneeded Variables\n",
        "df5= df5.drop(columns= ['TIMESTAMP','DEPARTURE_WITH_YEAR','ARRIVAL_WITH_YEAR', 'IS_ARRIVAL_BEFORE_DEPARTURE'], axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sr8TfeK9OCi",
        "colab_type": "text"
      },
      "source": [
        "## Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNGWYzhMuTJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df5.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yczll7rA8eq_",
        "colab_type": "text"
      },
      "source": [
        "> Apparently we have some problems from Missing Values to DEVICE. Don't worry about the Missing values of the EXTRA_BAGGAGE variable that is our response variable and the 30,000 Missing values presented come from the test sample and are just the values we want to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKGY0hPj8uAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting column DISTANCE to numeric. For this purpose, I'll cut the distance in the \",\"\n",
        "df6= df5.copy()\n",
        "df6[['DISTANCE_2','DISTANCE_REST']] = df6['DISTANCE'].str.split(\",\",expand=True)\n",
        "df6['DISTANCE_2']= pd.to_numeric(df6['DISTANCE_2'])\n",
        "df6[['HAUL_TYPE','DISTANCE','DISTANCE_2','DISTANCE_REST']].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck_pA2QIAIkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df6.groupby('HAUL_TYPE').agg({'DISTANCE_2': ['min', 'median', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huvfr3jfAtbQ",
        "colab_type": "text"
      },
      "source": [
        "Something strange with the minimum of DISTANCE_2. No sense DOMESTIC = 0. Much less INTERCONTINENTAL = 0. Let's investigate this a little further. However, I will work with DISTANCE_2 (following I will rename DISTANCE_2 TO DISTANCE) and disregard DISTANCE_REST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ2buWxxBEGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df6= df6.drop(columns= ['DISTANCE_REST','DISTANCE'], axis= 1)\n",
        "df6= df6.rename({'DISTANCE_2': 'DISTANCE'}, axis=1)\n",
        "df6.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaKP87NP9NBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many cases where DISTANCE = 0?\n",
        "df6[['DISTANCE']][df6['DISTANCE']==0].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq8626SFDzW1",
        "colab_type": "text"
      },
      "source": [
        "There are 288 records where DISTANCE = 0. I consider these records to be Missing Values. I will impute missing values based on HAUL_TYPE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-1Uh4bHDj8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_by__HAUL_TYPE= df6.groupby('HAUL_TYPE')['DISTANCE'].median()\n",
        "median_by__HAUL_TYPE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZHi8dwDAZWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_DISTANCE_DOMESTIC= median_by__HAUL_TYPE[1]\n",
        "median_DISTANCE_CONTINENTAL= median_by__HAUL_TYPE[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaXPDivK_2rG",
        "colab_type": "text"
      },
      "source": [
        "Median for DISTANCE when HAUL_TYPE = 'DOMESTIC' - I will use this value for missing values of DISTANCE when HAUL_TYPE = 'DOMESTIC'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inI5b46mC59c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_DISTANCE_DOMESTIC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQT6HQUMAFPi",
        "colab_type": "text"
      },
      "source": [
        "Median for DISTANCE when HAUL_TYPE = 'CONTINENTAL' - I will use this value for missing values of DISTANCE when HAUL_TYPE = 'CONTINENTAL'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8US59Q_DIrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_DISTANCE_CONTINENTAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1adzZo47EwjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Identifying Missing Values in DISTANCE. In this case, zeros.\n",
        "df6.loc[df6['DISTANCE'] == 0, 'DISTANCE']= np.nan\n",
        "\n",
        "# Checking Missing Values\n",
        "df6.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaAjeTcnH24a",
        "colab_type": "text"
      },
      "source": [
        "Let's treat Missing Values in DISTANCE and DEVICE below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFerujs2OUYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Missing Value imputation for DOMESTIC\n",
        "df6['DISTANCE'] = np.where(((df6['DISTANCE'].isnull()) & (df6['HAUL_TYPE'] ==\"DOMESTIC\")), median_DISTANCE_DOMESTIC, df6['DISTANCE'])\n",
        "\n",
        "# Missing Value imputation for INTERCONTINENTAL\n",
        "df6['DISTANCE'] = np.where(((df6['DISTANCE'].isnull()) & (df6['HAUL_TYPE'] ==\"INTERCONTINENTAL\")), median_DISTANCE_CONTINENTAL, df6['DISTANCE'])\n",
        "\n",
        "# Show some statistics\n",
        "df6.groupby('HAUL_TYPE').agg({'DISTANCE': ['min', 'median', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_H6goQqPOwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking Missing Values\n",
        "df6.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hnjGvFkPhQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Treating Missing Values of DEVICE\n",
        "df6['DEVICE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT7DglEqD14R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing NaN's of DEVICE with 'NO_DEVICE'\n",
        "df6[\"DEVICE\"].fillna(\"NO_DEVICE\", inplace= True)\n",
        "\n",
        "# Checking Missing Values\n",
        "df6.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No6lri5nwJhu",
        "colab_type": "text"
      },
      "source": [
        "As we can see above, missing values have been addressed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3isnpVTEwIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking...\n",
        "df6['DEVICE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neux3RWbEzQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df7= df6.copy()\n",
        "df7.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G_pCw2FUDhy",
        "colab_type": "text"
      },
      "source": [
        "# Handling Outliers in DISTANCE using IQR-Score\n",
        "> Consider the following output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HjMhbRJUMAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some statistics before outlier treatment in DISTANCE\n",
        "df7.groupby('HAUL_TYPE').agg({'DISTANCE': ['min', 'median', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W294A2UDXHJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(df7['DISTANCE'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtaWdM8kXhZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make boxplot with Catplot\n",
        "plt.rcdefaults()\n",
        "sns.catplot(x='HAUL_TYPE', y='DISTANCE', kind=\"box\", data=df7, height=4, aspect=1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32zBIQhvCdoq",
        "colab_type": "text"
      },
      "source": [
        "As we can see above, we have some outliers in the DISTANCE variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wz2lErneMH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "threshold = 3\n",
        "\n",
        "df_DOMESTIC= df7[df7['HAUL_TYPE']== 'DOMESTIC']\n",
        "df_CONTINENTAL= df7[df7['HAUL_TYPE']== 'CONTINENTAL']\n",
        "df_INTERCONTINENTAL= df7[df7['HAUL_TYPE']== 'INTERCONTINENTAL']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjSnYvRntbhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_DOMESTIC['HAUL_TYPE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFsx69SMtcyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_CONTINENTAL['HAUL_TYPE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDaEnt_6tdcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_INTERCONTINENTAL['HAUL_TYPE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeK-i-blDAP2",
        "colab_type": "text"
      },
      "source": [
        "Calculating IQR-Score for each HAULT_TYPE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK9nQB33BkMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IQR-Score\n",
        "Q1_DOMESTIC = df_DOMESTIC['DISTANCE'].quantile(0.25)\n",
        "Q3_DOMESTIC = df_DOMESTIC['DISTANCE'].quantile(0.75)\n",
        "IQR_DOMESTIC = Q3_DOMESTIC - Q1_DOMESTIC\n",
        "\n",
        "Q1_CONTINENTAL = df_CONTINENTAL['DISTANCE'].quantile(0.25)\n",
        "Q3_CONTINENTAL = df_CONTINENTAL['DISTANCE'].quantile(0.75)\n",
        "IQR_CONTINENTAL = Q3_CONTINENTAL - Q1_CONTINENTAL\n",
        "\n",
        "Q1_INTERCONTINENTAL = df_INTERCONTINENTAL['DISTANCE'].quantile(0.25)\n",
        "Q3_INTERCONTINENTAL = df_INTERCONTINENTAL['DISTANCE'].quantile(0.75)\n",
        "IQR_INTERCONTINENTAL = Q3_INTERCONTINENTAL - Q1_INTERCONTINENTAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6osGd3OpCy_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Excluding Outliers based on IQR-Score:\n",
        "df_DOMESTIC_IQR = df_DOMESTIC[~((df_DOMESTIC['DISTANCE'] < (Q1_DOMESTIC-1.5*IQR_DOMESTIC)) |(df_DOMESTIC['DISTANCE'] > (Q3_DOMESTIC+1.5*IQR_DOMESTIC)))]\n",
        "df_DOMESTIC_IQR.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ3EkovWII_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_CONTINENTAL.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW58fhU8Hnl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_CONTINENTAL_IQR = df_CONTINENTAL[~((df_CONTINENTAL['DISTANCE'] < (Q1_CONTINENTAL-1.5*IQR_CONTINENTAL)) |(df_CONTINENTAL['DISTANCE'] > (Q3_CONTINENTAL+1.5*IQR_CONTINENTAL)))]\n",
        "df_CONTINENTAL_IQR.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiB5X_pOIPu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_INTERCONTINENTAL.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCb0lCe7ISJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_INTERCONTINENTAL_IQR = df_INTERCONTINENTAL[~((df_INTERCONTINENTAL['DISTANCE'] < (Q1_INTERCONTINENTAL-1.5*IQR_INTERCONTINENTAL)) |(df_INTERCONTINENTAL['DISTANCE'] > (Q3_INTERCONTINENTAL+1.5*IQR_INTERCONTINENTAL)))]\n",
        "df_INTERCONTINENTAL_IQR.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30cHLd7YIhBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_IQR = df_DOMESTIC_IQR.append(df_CONTINENTAL_IQR, sort= True)\n",
        "df_IQR = df_IQR.append(df_INTERCONTINENTAL_IQR, sort= True)\n",
        "df_IQR.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF_kLEjCI7MZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "80000-76135"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yIZsGIpD-jJ",
        "colab_type": "text"
      },
      "source": [
        "Based on IQR-Score, we will lose 3,865 rows/records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAAkw_f6JJ_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_IQR.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqphSHw9JB-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make boxplot with Catplot\n",
        "plt.rcdefaults()\n",
        "sns.catplot(x='HAUL_TYPE', y='DISTANCE', kind=\"box\", data=df_IQR, height=4, aspect=1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QNerwPrET5x",
        "colab_type": "text"
      },
      "source": [
        "Note, however, that we do not have as many outliers as before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8h_v9uxJXGU",
        "colab_type": "text"
      },
      "source": [
        "Response-variable distribution after outlier treatment by IQR-Score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtIK5YQKJvvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BEFORE Outlier treatment in DISTANCE variable\n",
        "df7['EXTRA_BAGGAGE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSkr7dt1J7pX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AFTER Outlier treatment in DISTANCE variable\n",
        "df_IQR['EXTRA_BAGGAGE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O6d8LLPKCpM",
        "colab_type": "text"
      },
      "source": [
        "Small loss ... So I will continue with the database treated for outliers by IQR-Score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hp2mrxUKTxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DISTANCE BEFORE Outlier's treatment\n",
        "df7.groupby('HAUL_TYPE').agg({'DISTANCE': ['min', 'median', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdkZdv2cJv5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DISTANCE AFTER Outlier's treatment\n",
        "df_IQR.groupby('HAUL_TYPE').agg({'DISTANCE': ['min', 'median', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcvZ3zpSLFgp",
        "colab_type": "text"
      },
      "source": [
        "Note that the median has changed slightly when comparing before and after outlier treatment. I'll continue anyway, because I don't see it as a problem ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_EvuuvBL_yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(df_IQR['DISTANCE'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5nGTv5SF-JA",
        "colab_type": "text"
      },
      "source": [
        "# Binning numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIf8bQdKGFbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df8= df_IQR.copy()\n",
        "df8['EXTRA_BAGGAGE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iVPwA1-RnbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_Var_Target= {True: 1, False: 0}\n",
        "df8['EXTRA_BAGGAGE']= df8['EXTRA_BAGGAGE'].map(d_Var_Target)\n",
        "df8.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLb0378PNyGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df8.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_n9ofbINQTO",
        "colab_type": "text"
      },
      "source": [
        "## Treating numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs0RFUInaCCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df8['ARRIVAL_DEPARTURE'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkZeV3IVaMfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make boxplot with Catplot\n",
        "plt.rcdefaults()\n",
        "sns.catplot(x='HAUL_TYPE', y='ARRIVAL_DEPARTURE', kind=\"box\", data=df8, height=4, aspect=1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GbbV-b2H3R4",
        "colab_type": "text"
      },
      "source": [
        "Binning DISTANCE..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Ish_OrRNiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df8['DISTANCE_CAT']= pd.cut(df8['DISTANCE'], 10)\n",
        "df8= df8.drop(columns= ['DISTANCE'], axis= 1)\n",
        "df8.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-ie4P2TRDhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df8['DISTANCE_CAT'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbFDWd_JEZw",
        "colab_type": "text"
      },
      "source": [
        "## Treating categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ5wWSFNIZGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df9= df8.copy()\n",
        "df9.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGzOYgPYMv6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df10 = pd.get_dummies(df9, columns=['DISTANCE_CAT', 'ADULTS','ARRIVAL_DEPARTURE','CHILDREN','GDS','INFANTS','NO_GDS','DEVICE', 'HAUL_TYPE', 'PRODUCT', 'SMS', 'TRAIN', 'TRIP_TYPE', 'WEBSITE'], drop_first=True)\n",
        "df10.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IoUBan0QJWW",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biWIx8luRJ05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier,AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import RidgeClassifier, PassiveAggressiveClassifier, SGDClassifier, LogisticRegressionCV, LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier # Multi-Layer Perceptron Classifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwJtOjFmQOUy",
        "colab_type": "text"
      },
      "source": [
        "## Train/Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4vW5cd940j7",
        "colab_type": "text"
      },
      "source": [
        "The following is the training sample, which we will balance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbryDVvsPJOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df11= df10.copy()\n",
        "X_train= df11[df11['EXTRA_BAGGAGE'].notna()]\n",
        "X_train= X_train.drop(columns= ['EXTRA_BAGGAGE'], axis= 1)\n",
        "\n",
        "y_train= df11[df11['EXTRA_BAGGAGE'].notna()]\n",
        "y_train= y_train['EXTRA_BAGGAGE']\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4G64qId5CR3",
        "colab_type": "text"
      },
      "source": [
        "The following is the validation sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU8TVpLP4ySp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test= df11[df11['EXTRA_BAGGAGE'].isna()]\n",
        "X_test= X_test.drop(columns= ['EXTRA_BAGGAGE'], axis= 1)\n",
        "\n",
        "y_test= df11[df11['EXTRA_BAGGAGE'].isna()]\n",
        "y_test= y_test['EXTRA_BAGGAGE']\n",
        "\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDg9x1QeQV0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmWU_GNjQYtM",
        "colab_type": "text"
      },
      "source": [
        "Importance Sampling through 'Random Forest':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYcSENtTQbey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier(n_estimators = 500, max_depth=12)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "rf_y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "pd.Series(rf_clf.feature_importances_, index = X_train.columns).nlargest(12).plot(kind = 'barh',\n",
        "                                                                               figsize = (10, 10),\n",
        "                                                                              title = 'Feature importance from RandomForest').invert_yaxis();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEPziob35XJs",
        "colab_type": "text"
      },
      "source": [
        "As we can see above, the top 10 most important features are:\n",
        "\n",
        "01. NO_GDS_1;\n",
        "02. HAUL_TYPE_INTERCONTINENTAL;\n",
        "03. GDS_1;\n",
        "04. ADULTS_1;\n",
        "05. ARRIVAL_DEPARTURE_3;\n",
        "06. ADULTS_2;\n",
        "07. TRIP_TYPE_ROUND_TRIP;\n",
        "08. ARRIVAL_DEPARTURE_9;\n",
        "09. TRIP_TYPE_ONE_WAY;\n",
        "10. ARRIVAL_DEPARTURE_2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGvmZ07J6j_H",
        "colab_type": "text"
      },
      "source": [
        "Next, we will apply the following estimators / classifiers to the training sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VTcZsjIQfwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_Estimators = [('KNeighborsClassifier', KNeighborsClassifier(3)),\n",
        "               ('SVC', SVC(kernel=\"rbf\", C= 10, probability=True)),\n",
        "               ('NuSVC', NuSVC(probability=True)),\n",
        "               ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
        "               ('RandomForestClassifier', RandomForestClassifier()),\n",
        "               ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
        "               ('RidgeClassifier', RidgeClassifier()),\n",
        "               ('AdaBoostClassifier', AdaBoostClassifier()),\n",
        "               ('GaussianNB', GaussianNB()),\n",
        "               ('BernoulliNB', BernoulliNB()),\n",
        "               ('PassiveAggressiveClassifier', PassiveAggressiveClassifier()),\n",
        "               ('LinearSVC', LinearSVC()),\n",
        "               ('SGDClassifier', SGDClassifier(loss='log', penalty='elasticnet')),\n",
        "               ('LogisticRegression', LogisticRegression()),\n",
        "               ('NearestCentroid', NearestCentroid()),\n",
        "               ('Perceptron', Perceptron()),\n",
        "               ('MLPClassifier', MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)),\n",
        "               ('LGBMClassifier', LGBMClassifier()),\n",
        "               ('BaggingClassifier', BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)),\n",
        "               ('GaussianProcessClassifier', GaussianProcessClassifier()),\n",
        "               ('XGBClassifier', XGBClassifier(n_estimators= 1000,max_depth= 4,objective='reg:logistic',scale_pos_weight=1)),\n",
        "               ('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators = 750, max_features = 'sqrt', max_depth = 35,  criterion = 'entropy', random_state = 20111974))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kYW_yzqvNdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THOwOxv2sg53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DT= DecisionTreeClassifier(max_depth= 5)\n",
        "DT.fit(X_train,y_train)\n",
        "y_pred = DT.predict(X_test)\n",
        "DT.score(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7pIuT7EzR6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_score(y_test, y_pred, average= 'weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTpgOTh0tUQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF= RandomForestClassifier(max_depth= 5, n_estimators= 1000, n_jobs= -1)\n",
        "RF.fit(X_train,y_train)\n",
        "y_pred = RF.predict(X_test)\n",
        "RF.score(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH9mnGbl0B6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_score(y_test, y_pred, average= 'weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3KXiSpwxpdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "AB = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=8),n_estimators=600)\n",
        "AB.fit(X_train,y_train)\n",
        "y_pred = AB.predict(X_test)\n",
        "AB.score(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKrcn6Dg0XRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_score(y_test, y_pred, average= 'weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEYkTCm73Ben",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "ET= ExtraTreesClassifier(n_estimators = 750, max_features = 'sqrt', max_depth = 35,  criterion = 'entropy', random_state = 20111974)\n",
        "ET.fit(X_train,y_train)\n",
        "y_pred = ET.predict(X_test)\n",
        "ET.score(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXMRgSZ12amt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_score(y_test, y_pred, average= 'weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHcqjQNf1VSP",
        "colab_type": "text"
      },
      "source": [
        "### Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1keolu3V1XDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cart = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "KFold= StratifiedKFold(n_splits= 10, shuffle=True)\n",
        "\n",
        "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees)\n",
        "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6alHA0z9cHe",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "> As I'll submit a binary output, I need to use a F1-Score, as suggested in the challenge. Firstly, let's understand what's F1-Score metric:\n",
        "\n",
        "* **Precision**: When the model predicts positive, how often is it correct? A low precision can also indicate a large number of False Positives.\n",
        "\n",
        "    $Precision= \\frac{TruePositives}{TruePositive + FalsePositives}$\n",
        "\n",
        "* **Recall**: Recall is the number of True Positives divided by the number of True Positives and the number of False Negatives. Put another way it is the number of positive predictions divided by the number of positive class values in the test data. It is also called Sensitivity or the True Positive Rate. A low recall indicates many False Negatives.\n",
        "\n",
        "    $Recall= \\frac{TruePositives}{TruePositives + FalseNegatives}$\n",
        "\n",
        "* **F1 Score**: F1 score conveys the balance between the precision and the recall.\n",
        "\n",
        "    $F1= 2*\\frac{Precision*Recall}{Precision+Recall}$\n",
        "\n",
        "Source: [Classification Accuracy is Not Enough: More Performance Measures You Can Use](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNO3IhZO905D",
        "colab_type": "text"
      },
      "source": [
        "## Interpretation\n",
        "> A good F1 score means that you have low false positives and low false negatives, so you’re correctly identifying real threats and you are not disturbed by false alarms. \n",
        ">> An F1 score is considered perfect when it’s 1, while the model is a total failure when it’s 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trV3daa7C4l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_pred = vc.predict(X_test)\n",
        "f1_score(y_test, y_pred, average='weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfVFWzneRgoi",
        "colab_type": "text"
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvQ1R-oRiQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cart = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=20111974)\n",
        "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}