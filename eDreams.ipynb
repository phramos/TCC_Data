{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/eDreams/blob/master/eDreams2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17LuXi1voKCf",
        "colab_type": "text"
      },
      "source": [
        "# Install & Load Main Python libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQy1h2RVoVxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bamboolib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIMVpjquns-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import bamboolib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhymf5HmfuyW",
        "colab_type": "text"
      },
      "source": [
        "# Load dataframes: training & test sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWfL-XJFnZIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_train= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/train.csv?token=AGDJQ62XLVU7JXF5SI6OC625WBWJE\"\n",
        "url_test= \"https://raw.githubusercontent.com/MathMachado/eDreams/master/Dataframes/test.csv?token=AGDJQ64SG2DNKAW4RWBFGZS5WBWHS\"\n",
        "\n",
        "# Stacking training and validation samples for a single treatment\n",
        "df_train= pd.read_csv(url_train, sep= \";\", index_col='ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "df_test= pd.read_csv(url_test, sep= \";\", index_col='ID', parse_dates = ['DEPARTURE', 'ARRIVAL'])\n",
        "\n",
        "# Resetting the test sample indices\n",
        "df_test.index= range(50000, 80000)\n",
        "\n",
        "# merge train and test\n",
        "df = df_train.append(df_test, sort= True)\n",
        "\n",
        "# Records training and test dataframe indexes to separate these dataframes later\n",
        "train_index = df_train.index\n",
        "test_index = df_test.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EItCRxK9OWVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbkvqUL-PMmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDIkBDEaP_eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puYrD8S-QnuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpAcrYpUQEL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWPMAIX1vMuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDANOjiKf4Qh",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrH6yLyI_LIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T= df.copy()\n",
        "# Capturing the Company: First 2 positions of WEBSITE.\n",
        "df_T['COMPANY']= df_T['WEBSITE'].str[0:2].astype(str)\n",
        "\n",
        "# Capturing the Country: rest of the string of WEBSITE.\n",
        "df_T['COUNTRY']= df_T['WEBSITE'].str[2:len(df['WEBSITE'])].astype(str)\n",
        "\n",
        "df_T.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbiq3bb5BFOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COMPANY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL2tFUwhBdwB",
        "colab_type": "text"
      },
      "source": [
        "There's no 'TL'. So I'll replace 'TL' by 'MV'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Wf9MUqBsof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COMPANY']= df_T['COMPANY'].replace('TL', 'MV')\n",
        "df_T['COMPANY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyo-zI5aAz62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jVCElWtCceJ",
        "colab_type": "text"
      },
      "source": [
        "I'll consider countries with 3 characters as a Missing value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P86wEaspCljP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COUNTRY']= df_T['COUNTRY'].replace(['PLC', 'DEC', 'DKC', 'FRC'], 'MV')\n",
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjGHXqYODAbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T['COUNTRY']= df_T['COUNTRY'].replace(['UK'], 'GB')\n",
        "df_T['COUNTRY'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QRlW3cf6M5",
        "colab_type": "text"
      },
      "source": [
        "## Treating date variables\n",
        "> Since there is no information regarding the year of the transaction, I will assume that the transactions are from 2018 or 2019. I will assign the year conveniently from the analysis of the variables DEPARTURE and ARRIVAL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myZk676JnqrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2= df_T.copy()\n",
        "df2['DEPARTURE_WITH_YEAR']= df2['DEPARTURE'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR']= df2['ARRIVAL'] +'/2018'\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= df2['ARRIVAL'] +'/2019'\n",
        "\n",
        "df2['DEPARTURE_WITH_YEAR']= pd.to_datetime(df2['DEPARTURE_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR'])\n",
        "df2['ARRIVAL_WITH_YEAR_FIXED']= pd.to_datetime(df2['ARRIVAL_WITH_YEAR_FIXED'])\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haF1q_a0gKcu",
        "colab_type": "text"
      },
      "source": [
        "As we do not have year information, in some cases/rows we have ARRIVAL < DEPARTURE. Let's take a look in some cases where ARRIVAL < DEPARTURE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucsI7q6LhjEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3= df2.copy()\n",
        "\n",
        "# I created the variable IS_ARRIVAL_BEFORE_DEPARTURE to help us identify when ARRIVAL < DEPARTURE:\n",
        "df3['IS_ARRIVAL_BEFORE_DEPARTURE']= df3['ARRIVAL_WITH_YEAR'] < df3['DEPARTURE_WITH_YEAR']\n",
        "\n",
        "# Fixing cases when ARRIVAL < DEPARTURE\n",
        "df3.loc[df3['IS_ARRIVAL_BEFORE_DEPARTURE']== True, 'ARRIVAL_WITH_YEAR']= df3['ARRIVAL_WITH_YEAR_FIXED']\n",
        "df3[['ARRIVAL', 'DEPARTURE', 'DEPARTURE_WITH_YEAR', 'ARRIVAL_WITH_YEAR']][df3['IS_ARRIVAL_BEFORE_DEPARTURE']== True].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGfnRkrniBH3",
        "colab_type": "text"
      },
      "source": [
        "> Take for example line 15 (output above):\n",
        "* DEPARTURE= December 15th;\n",
        "* ARRIVAL= January 29th.\n",
        "\n",
        "> Without information for the year, then ARRIVAL < DEPARTURE. However, look at the variables DEPARTURE_WITH_YEAR and ARRIVAL_WITH_YEAR above:\n",
        "* DEPARTURE_WITH_YEAR= December 15th of 2018;\n",
        "* ARRIVAL_WITH_YEAR= January 29th of 2019.\n",
        "\n",
        "In this case, we fixed the problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtS019CfldHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop the unnecessary variables:\n",
        "df3= df3.drop(columns= ['DEPARTURE', 'ARRIVAL', 'ARRIVAL_WITH_YEAR_FIXED', 'WEBSITE'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MknGmW_lGIz",
        "colab_type": "text"
      },
      "source": [
        "Next, we calculate the variable ARRIVAL_DEPARTURE = ARRIVAL_WITH_YEAR - DEPARTURE_WITH_YEAR:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ohReuC6Px3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the variable ARRIVAL_DEPARTURE:\n",
        "df3['ARRIVAL_DEPARTURE']= (df3['ARRIVAL_WITH_YEAR']-df3['DEPARTURE_WITH_YEAR']).dt.days.astype(int)\n",
        "\n",
        "# Show some cases:\n",
        "df3[['DEPARTURE_WITH_YEAR', 'ARRIVAL_WITH_YEAR', 'ARRIVAL_DEPARTURE']].head() #[df3['IS_ARRIVAL_BEFORE_DEPARTURE']== True].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb7YWHbtdvV-",
        "colab_type": "text"
      },
      "source": [
        "> Something strange with the variable ARRIVAL_DEPARTURE. Take a look at the line 2 (above). We have:\n",
        "* DEPARTURE_WITH_YEAR= 2018-07-29\n",
        "* ARRIVAL_WITH_YEAR= 2018-08-19\n",
        "\n",
        "It is 21 days between DEPARTURE and ARRIVAL!\n",
        "\n",
        "Let's take a look in some statistics below. For example, let's look at the proportion of cases where ARRIVAL_DEPARTURE > 5. I am using 5 as an example, but I consider 5 a long time between departure and arrival."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDdSaImBoOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3_Zoom= df3[df3['ARRIVAL_DEPARTURE'] > 5]\n",
        "df3_Zoom.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCab0H3crqRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X38iPLrIr5Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3.groupby('TRIP_TYPE').agg({'ARRIVAL_DEPARTURE': ['min', 'median','max']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSa524ChsMjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3.groupby('HAUL_TYPE').agg({'ARRIVAL_DEPARTURE': ['min', 'median','max']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmTkGEOXsgPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3.groupby(['TRIP_TYPE','HAUL_TYPE']).agg({'ARRIVAL_DEPARTURE': ['min', 'mean', 'median','max']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TAukV-OpJ9s",
        "colab_type": "text"
      },
      "source": [
        "Strangely, many cases over 5 days. \n",
        "\n",
        "Below, I present the distribution of the ARRIVAL_DEPARTURE variable. As we can see, there are cases older than 50 days!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfyphUD8ecHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(df3['ARRIVAL_DEPARTURE'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bp0-Ym9fENa",
        "colab_type": "text"
      },
      "source": [
        "Below I present some descriptive statistics for ARRIVAL_DEPARTURE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3HxlKdCdxUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3.groupby('HAUL_TYPE').agg({'ARRIVAL_DEPARTURE': ['min', 'median', 'mean', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZZpOTs8qpeW",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the Boxplot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8M4TUXJfDDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcdefaults()\n",
        "sns.catplot(y='ARRIVAL_DEPARTURE', kind=\"box\", data=df3, height=4, aspect=1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t8WnF3yIZxet",
        "colab": {}
      },
      "source": [
        "df3['TRIP_TYPE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWh7qJmLuDF-",
        "colab_type": "text"
      },
      "source": [
        "Function to detect Outliers based on IQR-Score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKDDxJ2grbuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that identify outlier using IQR-Score:\n",
        "def IQR_Score_Outlier_Detect(column):\n",
        "    global df_T\n",
        "\n",
        "    Q1 = df_T[column].quantile(0.25)\n",
        "    Q3 = df_T[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    Lim_Inf= Q1-1.5*IQR\n",
        "    Lim_Sup= Q3+1.5*IQR\n",
        "    print(Lim_Inf, Lim_Sup)\n",
        "\n",
        "    # Replace outliers by Lim_Inf and Lim_Sup\n",
        "    df_T[column+'_IQR'] = np.where(((df_T[column] < Lim_Inf)), Lim_Inf, df_T[column])\n",
        "    df_T[column+'_IQR'] = np.where(((df_T[column] > Lim_Sup)), Lim_Sup, df_T[column])\n",
        "\n",
        "    # Identify the outlier\n",
        "    #df_T[column+'_IS_OUTLIER_IQR']= np.where(((df_T[column] < Lim_Inf)), True, False)\n",
        "    #df_T[column+'_IS_OUTLIER_IQR']= np.where(((df_T[column] > Lim_Sup)), True, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckj7CwK7u38Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T= df3.copy()\n",
        "df_T['ARRIVAL_DEPARTURE_2']= df_T['ARRIVAL_DEPARTURE']\n",
        "IQR_Score_Outlier_Detect('ARRIVAL_DEPARTURE_2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ald65PwAT2C-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MecuYMd_c53G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deleting Unneeded Variables\n",
        "df4= df_T.copy()\n",
        "df4= df_T.drop(columns= ['TIMESTAMP','DEPARTURE_WITH_YEAR','ARRIVAL_WITH_YEAR', 'IS_ARRIVAL_BEFORE_DEPARTURE'], axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sr8TfeK9OCi",
        "colab_type": "text"
      },
      "source": [
        "## Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNGWYzhMuTJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yczll7rA8eq_",
        "colab_type": "text"
      },
      "source": [
        "> Apparently we have some problems from Missing Values to DEVICE. Don't worry about the Missing values of the EXTRA_BAGGAGE variable that is our response variable and the 30,000 Missing values presented come from the test sample and are just the values we want to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKGY0hPj8uAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting column DISTANCE to numeric. For this purpose, I'll cut the distance in the \",\"\n",
        "df6= df4.copy()\n",
        "df6[['DISTANCE_2','DISTANCE_REST']] = df6['DISTANCE'].str.split(\",\",expand=True)\n",
        "df6['DISTANCE_2']= pd.to_numeric(df6['DISTANCE_2'])\n",
        "df6[['HAUL_TYPE','DISTANCE','DISTANCE_2','DISTANCE_REST']].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck_pA2QIAIkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df6.groupby('HAUL_TYPE').agg({'DISTANCE_2': ['min', 'median', 'max', 'count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huvfr3jfAtbQ",
        "colab_type": "text"
      },
      "source": [
        "Something strange with the minimum of DISTANCE_2. No sense DOMESTIC = 0. Much less INTERCONTINENTAL = 0. Let's investigate this a little further. However, I will work with DISTANCE_2 (following I will rename DISTANCE_2 TO DISTANCE) and disregard DISTANCE_REST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ2buWxxBEGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df6= df6.drop(columns= ['DISTANCE_REST','DISTANCE'], axis= 1)\n",
        "df6= df6.rename({'DISTANCE_2': 'DISTANCE'}, axis=1)\n",
        "df6.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaKP87NP9NBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many cases where DISTANCE = 0?\n",
        "df6[['DISTANCE']][df6['DISTANCE']==0].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq8626SFDzW1",
        "colab_type": "text"
      },
      "source": [
        "There are 288 records where DISTANCE = 0. I consider these records to be Missing Values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-1Uh4bHDj8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_by__HAUL_TYPE= df6.groupby('HAUL_TYPE')['DISTANCE'].median()\n",
        "median_by__TRIP_TYPE= df6.groupby('TRIP_TYPE')['DISTANCE'].median()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1iCRujZ-o69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_by__HAUL_TYPE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WdQCpSt-qfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_by__TRIP_TYPE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUUukvjk_dM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_by__HAUL_TYPE[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZHi8dwDAZWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_DISTANCE_C= median_by__HAUL_TYPE[0]\n",
        "median_DISTANCE_D= median_by__HAUL_TYPE[1]\n",
        "median_DISTANCE_I= median_by__HAUL_TYPE[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jFtUvLb_o4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_DISTANCE_RT= median_by__TRIP_TYPE[2]\n",
        "median_DISTANCE_OW= median_by__TRIP_TYPE[1]\n",
        "median_DISTANCE_MD= median_by__TRIP_TYPE[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1adzZo47EwjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Identifying Missing Values in DISTANCE. In this case, zeros.\n",
        "df6.loc[df6['DISTANCE'] == 0, 'DISTANCE']= np.nan\n",
        "\n",
        "# Checking Missing Values\n",
        "df6.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaAjeTcnH24a",
        "colab_type": "text"
      },
      "source": [
        "Let's treat Missing Values in DISTANCE and DEVICE below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFerujs2OUYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df6['DISTANCE_HT']= df6['DISTANCE']\n",
        "df6['DISTANCE_TT']= df6['DISTANCE']\n",
        "\n",
        "# Missing Value imputation for DOMESTIC\n",
        "df6['DISTANCE_HT'] = np.where(((df6['DISTANCE_HT'].isnull()) & (df6['HAUL_TYPE'] ==\"DOMESTIC\")), median_DISTANCE_D, df6['DISTANCE_HT'])\n",
        "\n",
        "# Missing Value imputation for INTERCONTINENTAL\n",
        "df6['DISTANCE_HT'] = np.where(((df6['DISTANCE_HT'].isnull()) & (df6['HAUL_TYPE'] ==\"INTERCONTINENTAL\")), median_DISTANCE_I, df6['DISTANCE_HT'])\n",
        "\n",
        "# Missing Value imputation for CONTINENTAL\n",
        "df6['DISTANCE_HT'] = np.where(((df6['DISTANCE_HT'].isnull()) & (df6['HAUL_TYPE'] ==\"CONTINENTAL\")), median_DISTANCE_C, df6['DISTANCE_HT'])\n",
        "\n",
        "##############\n",
        "# Missing Value imputation for MULTI_DESTINATION\n",
        "df6['DISTANCE_TT'] = np.where(((df6['DISTANCE_TT'].isnull()) & (df6['TRIP_TYPE'] ==\"MULTI_DESTINATION\")), median_DISTANCE_MD, df6['DISTANCE_TT'])\n",
        "\n",
        "# Missing Value imputation for ONE_WAY\n",
        "df6['DISTANCE_TT'] = np.where(((df6['DISTANCE_TT'].isnull()) & (df6['TRIP_TYPE'] ==\"ONE_WAY\")), median_DISTANCE_OW, df6['DISTANCE_TT'])\n",
        "\n",
        "# Missing Value imputation for ROUND_TRIP\n",
        "df6['DISTANCE_TT'] = np.where(((df6['DISTANCE_TT'].isnull()) & (df6['TRIP_TYPE'] ==\"ROUND_TRIP\")), median_DISTANCE_RT, df6['DISTANCE_TT'])\n",
        "\n",
        "df6= df6.drop(columns= ['DISTANCE'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_H6goQqPOwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking Missing Values\n",
        "df6.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hnjGvFkPhQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Treating Missing Values of DEVICE\n",
        "df6['DEVICE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT7DglEqD14R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing NaN's of DEVICE with 'NO_DEVICE'\n",
        "df6[\"DEVICE\"].fillna(\"NO_DEVICE\", inplace= True)\n",
        "\n",
        "# Checking Missing Values\n",
        "df6.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No6lri5nwJhu",
        "colab_type": "text"
      },
      "source": [
        "As we can see above, missing values have been addressed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3isnpVTEwIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking...\n",
        "df6['DEVICE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neux3RWbEzQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df7= df6.copy()\n",
        "df7.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G_pCw2FUDhy",
        "colab_type": "text"
      },
      "source": [
        "# Handling Outliers in DISTANCE using IQR-Score\n",
        "> Consider the following output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W294A2UDXHJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(df7['DISTANCE_HT'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32zBIQhvCdoq",
        "colab_type": "text"
      },
      "source": [
        "As we can see above, we have some outliers in the DISTANCE variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy4IXD6vux8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_T= df7.copy()\n",
        "df_T['DISTANCE_HT_2']= df_T['DISTANCE_HT']\n",
        "df_T['DISTANCE_TT_2']= df_T['DISTANCE_TT']\n",
        "\n",
        "IQR_Score_Outlier_Detect('DISTANCE_HT_2')\n",
        "IQR_Score_Outlier_Detect('DISTANCE_TT_2')\n",
        "\n",
        "df_T.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8h_v9uxJXGU",
        "colab_type": "text"
      },
      "source": [
        "Response-variable distribution after outlier treatment by IQR-Score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtIK5YQKJvvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df8= df_T.copy()\n",
        "\n",
        "# BEFORE Outlier treatment in DISTANCE variable\n",
        "df8['EXTRA_BAGGAGE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5nGTv5SF-JA",
        "colab_type": "text"
      },
      "source": [
        "# Binning numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIf8bQdKGFbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df9= df8.copy()\n",
        "df9['EXTRA_BAGGAGE'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iVPwA1-RnbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_Var_Target= {True: 1, False: 0}\n",
        "df9['EXTRA_BAGGAGE']= df9['EXTRA_BAGGAGE'].map(d_Var_Target)\n",
        "df9.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLb0378PNyGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df9.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_n9ofbINQTO",
        "colab_type": "text"
      },
      "source": [
        "## Treating numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Ish_OrRNiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_Vars_Num= ['DISTANCE_HT', 'DISTANCE_TT', 'DISTANCE_HT_2', 'DISTANCE_TT_2', 'DISTANCE_HT_2_IQR', 'DISTANCE_TT_2_IQR', 'ARRIVAL_DEPARTURE', 'ARRIVAL_DEPARTURE_2', 'ARRIVAL_DEPARTURE_2_IQR']\n",
        "for var in l_Vars_Num:\n",
        "    df9[var+'_CAT']= pd.cut(df9[var], 10)\n",
        "    df9= df9.drop(columns= [var], axis= 1)\n",
        "\n",
        "df9.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbFDWd_JEZw",
        "colab_type": "text"
      },
      "source": [
        "## Treating categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ5wWSFNIZGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df10= df9.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGzOYgPYMv6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df10 = pd.get_dummies(df10, columns=['DISTANCE_HT_CAT','DISTANCE_HT_2_CAT', 'DISTANCE_TT_CAT', 'DISTANCE_TT_2_CAT', 'DISTANCE_HT_2_IQR_CAT', 'DISTANCE_TT_2_IQR_CAT', 'ADULTS','ARRIVAL_DEPARTURE_CAT','ARRIVAL_DEPARTURE_2_CAT', 'ARRIVAL_DEPARTURE_2_IQR_CAT','CHILDREN','GDS','INFANTS','NO_GDS','DEVICE', 'HAUL_TYPE', 'PRODUCT', 'SMS', 'TRAIN', 'TRIP_TYPE', 'COMPANY', 'COUNTRY'], drop_first=True)\n",
        "df10.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IoUBan0QJWW",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwJtOjFmQOUy",
        "colab_type": "text"
      },
      "source": [
        "## Train/Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk_vdqSq6qD-",
        "colab_type": "text"
      },
      "source": [
        "### Balancing the training sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2KkVB2E6xCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df10['EXTRA_BAGGAGE'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLYbP16k9FBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(x= 'EXTRA_BAGGAGE', data= df10, palette= 'hls')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6wJwuU_7N5K",
        "colab_type": "text"
      },
      "source": [
        "So, I'll select 10,000 EXTRA_BAGGAGE= 0 and all EXTRA_BAGGAGE= 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgSKjsx87XTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Selecting all EXTRA_BAGGAGE= 1...\n",
        "df11_1= df10[df10['EXTRA_BAGGAGE']== 1]\n",
        "df11_1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2l6OrDl9xWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Selecting all EXTRA_BAGGAGE= 1...\n",
        "df11_temp= df10[df10['EXTRA_BAGGAGE']== 0]\n",
        "df11_0= df11_temp.sample(n= 10000)\n",
        "df11_0.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDQz1-6B-91o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df11= df11_1.append(df11_0)\n",
        "df11.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4vW5cd940j7",
        "colab_type": "text"
      },
      "source": [
        "The following is the training sample, which we will balance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbryDVvsPJOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df12= df11.copy()\n",
        "X= df12[df12['EXTRA_BAGGAGE'].notna()]\n",
        "X= X.drop(columns= ['EXTRA_BAGGAGE'], axis= 1)\n",
        "y= df12[['EXTRA_BAGGAGE']][df12['EXTRA_BAGGAGE'].notna()]\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmWU_GNjQYtM",
        "colab_type": "text"
      },
      "source": [
        "Importance Sampling through 'Random Forest':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYcSENtTQbey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier(n_estimators = 500, max_depth=15)\n",
        "rf_clf.fit(X, y)\n",
        "rf_y_pred = rf_clf.predict(X)\n",
        "\n",
        "pd.Series(rf_clf.feature_importances_, index = X.columns).nlargest(30).plot(kind = 'barh',\n",
        "                                                                               figsize = (9, 9),\n",
        "                                                                              title = 'Feature importance from RandomForest').invert_yaxis();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdOjU63dHH0M",
        "colab_type": "text"
      },
      "source": [
        "# Dropping variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmF1OA1mHjj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df13= df12.copy()\n",
        "df13.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNeSOFghHmHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df13= df13.drop(columns= ['DISTANCE_HT_2_CAT_(17792.7, 19766.0]', 'DISTANCE_TT_CAT_(2006.3, 3979.6]', 'DISTANCE_TT_CAT_(3979.6, 5952.9]', 'DISTANCE_TT_CAT_(5952.9, 7926.2]', 'DISTANCE_TT_CAT_(7926.2, 9899.5]', 'DISTANCE_TT_CAT_(9899.5, 11872.8]', 'DISTANCE_TT_CAT_(11872.8, 13846.1]', 'DISTANCE_TT_CAT_(13846.1, 15819.4]', 'DISTANCE_TT_CAT_(15819.4, 17792.7]', 'DISTANCE_TT_CAT_(17792.7, 19766.0]', 'DISTANCE_TT_2_CAT_(2006.3, 3979.6]', 'DISTANCE_TT_2_CAT_(3979.6, 5952.9]', 'DISTANCE_TT_2_CAT_(5952.9, 7926.2]', 'DISTANCE_TT_2_CAT_(7926.2, 9899.5]', 'DISTANCE_TT_2_CAT_(9899.5, 11872.8]', 'DISTANCE_TT_2_CAT_(11872.8, 13846.1]', 'DISTANCE_TT_2_CAT_(13846.1, 15819.4]', 'DISTANCE_TT_2_CAT_(15819.4, 17792.7]', 'DISTANCE_TT_2_CAT_(17792.7, 19766.0]'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwtGbrhOJXFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X= df13[df13['EXTRA_BAGGAGE'].notna()]\n",
        "X= X.drop(columns= ['EXTRA_BAGGAGE'], axis= 1)\n",
        "y= df13[['EXTRA_BAGGAGE']][df13['EXTRA_BAGGAGE'].notna()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7XJIUrbJjCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier(n_estimators = 500, max_depth=15)\n",
        "rf_clf.fit(X, y)\n",
        "rf_y_pred = rf_clf.predict(X)\n",
        "\n",
        "pd.Series(rf_clf.feature_importances_, index = X.columns).nlargest(30).plot(kind = 'barh',\n",
        "                                                                               figsize = (9, 9),\n",
        "                                                                              title = 'Feature importance from RandomForest').invert_yaxis();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cm1bE0oaTTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Create a list of feature names\n",
        "feat_labels = X.columns\n",
        "\n",
        "# Create a selector object that will use the random forest classifier to identify\n",
        "# features that have an importance of more than 0.005\n",
        "sfm = SelectFromModel(rf_clf, threshold=0.005)\n",
        "\n",
        "# Train the selector\n",
        "sfm.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIkDv4-8LySb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the names of the most important features\n",
        "l_Vars= []\n",
        "for feature_list_index in sfm.get_support(indices=True):\n",
        "    print(feat_labels[feature_list_index])\n",
        "    l_Vars.append(feat_labels[feature_list_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJSzhiDMd0oB",
        "colab_type": "text"
      },
      "source": [
        "Note below that we have reduced the number of columns/variables. Instead of 112, now we are working only with 28."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um6eDoo5cfGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2= df13[l_Vars][df13['EXTRA_BAGGAGE'].notna()]\n",
        "print(X2.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X2,y, test_size= 0.2)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGvmZ07J6j_H",
        "colab_type": "text"
      },
      "source": [
        "Next, we will apply the following estimators / classifiers to the training sample:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6alHA0z9cHe",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "> As I'll submit a binary output, I need to use a F1-Score, as suggested in the challenge. Firstly, let's understand what's F1-Score metric:\n",
        "\n",
        "* **Precision**: When the model predicts positive, how often is it correct? A low precision can also indicate a large number of False Positives.\n",
        "\n",
        "    $Precision= \\frac{TruePositives}{TruePositive + FalsePositives}$\n",
        "\n",
        "* **Recall**: Recall is the number of True Positives divided by the number of True Positives and the number of False Negatives. Put another way it is the number of positive predictions divided by the number of positive class values in the test data. It is also called Sensitivity or the True Positive Rate. A low recall indicates many False Negatives.\n",
        "\n",
        "    $Recall= \\frac{TruePositives}{TruePositives + FalseNegatives}$\n",
        "\n",
        "* **F1 Score**: F1 score conveys the balance between the precision and the recall.\n",
        "\n",
        "    $F1= 2*\\frac{Precision*Recall}{Precision+Recall}$\n",
        "\n",
        "Source: [Classification Accuracy is Not Enough: More Performance Measures You Can Use](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNO3IhZO905D",
        "colab_type": "text"
      },
      "source": [
        "## Interpretation\n",
        "> A good F1 score means that you have low false positives and low false negatives, so you’re correctly identifying real threats and you are not disturbed by false alarms. \n",
        ">> An F1 score is considered perfect when it’s 1, while the model is a total failure when it’s 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kYW_yzqvNdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBDGsVX4iypF",
        "colab_type": "text"
      },
      "source": [
        "### Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THOwOxv2sg53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DT= DecisionTreeClassifier(max_depth= 5)\n",
        "DT.fit(X_train, y_train)\n",
        "y_pred = DT.predict(X_test)\n",
        "f1_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMpXytI9dhj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A0y3ZEri2dY",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTpgOTh0tUQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF= RandomForestClassifier(max_depth= 5, n_estimators= 1000, n_jobs= -1)\n",
        "RF.fit(X_train,y_train)\n",
        "y_pred = RF.predict(X_test)\n",
        "f1_score(y_test, y_pred, average= 'weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQU2-hj4eAtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zEf-2Voi6DY",
        "colab_type": "text"
      },
      "source": [
        "### AdaBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3KXiSpwxpdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "AB = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=8),n_estimators=600)\n",
        "AB.fit(X_train,y_train)\n",
        "y_pred = AB.predict(X_test)\n",
        "f1_score(y_test, y_pred, average= 'weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st3XoaQEeDrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEi7K0kZi-ov",
        "colab_type": "text"
      },
      "source": [
        "### Extra Trees Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEYkTCm73Ben",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "ET= ExtraTreesClassifier(n_estimators = 750, max_features = 'sqrt', max_depth = 35,  criterion = 'entropy', random_state = 20111974)\n",
        "ET.fit(X_train,y_train)\n",
        "y_pred = ET.predict(X_test)\n",
        "f1_score(y_test, y_pred, average= 'weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej0RYhmAeGdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bQzAH7gjGB-",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdpausCbjH-T",
        "colab_type": "text"
      },
      "source": [
        "DecisionTreeClassifier presented better F1-Score. Finally, I will fine-tune the parameters to try to improve F1-Score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvTEjmTUjzIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_parameter = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150], 'min_samples_split': [2, 10, 20], 'min_samples_leaf': [1, 5, 10], 'max_leaf_nodes': [None, 5, 10, 20]}\n",
        "clf = GridSearchCV(DecisionTreeClassifier(), tree_parameter, cv= 5)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj2DlYdlj3nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "f1_score(y_test, y_pred, average= 'weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrM0jWHBm6bF",
        "colab_type": "text"
      },
      "source": [
        "As we can see, after fine tuning, I had a slight improvement in the value of F1-Score. So, my final F1-Score= 0.6666."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQekDqR7ncE2",
        "colab_type": "text"
      },
      "source": [
        "# Submitting my model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrL_MLi7n_EP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Val= df10[l_Vars][df10['EXTRA_BAGGAGE'].isna()]\n",
        "y_Val= df10[['EXTRA_BAGGAGE']][df10['EXTRA_BAGGAGE'].isna()]\n",
        "\n",
        "print(X_Val.shape, y_Val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHci3WoTlY5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Val['EXTRA_BAGGAGE'] = clf.predict(X_Val)\n",
        "y_pred_submission= X_Val[['EXTRA_BAGGAGE']]\n",
        "y_pred_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnjBBMglqfL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_submission['EXTRA_BAGGAGE']= y_pred_submission['EXTRA_BAGGAGE'].map({0.0: False, 1.0: True})\n",
        "y_pred_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1rxBI4toZ4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_submission.to_csv(r'eDreams_Submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
